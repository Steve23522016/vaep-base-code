{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from name_matching.name_matcher import NameMatcher\n",
    "\n",
    "# # define a dataset with bank names\n",
    "# df_companies_a = pd.DataFrame({'Company name': [\n",
    "#         'Industrial and Commercial Bank of China Limited',\n",
    "#         'China Construction Bank',\n",
    "#         'Agricultural Bank of China',\n",
    "#         'Bank of China',\n",
    "#         'JPMorgan Chase',\n",
    "#         'Mitsubishi UFJ Financial Group',\n",
    "#         'Bank of America',\n",
    "#         'HSBC',\n",
    "#         'BNP Paribas',\n",
    "#         'CrÃ©dit Agricole']})\n",
    "\n",
    "# # alter each of the bank names a bit to test the matching\n",
    "# df_companies_b = pd.DataFrame({'name': [\n",
    "#         'Steve',\n",
    "#         'Mitsubishi Financial Group',\n",
    "#         'Construction Bank China',\n",
    "#         'Agricultural Bank',\n",
    "#         'Bank of Amerika',\n",
    "#         'BNP Parisbas',\n",
    "#         'JP Morgan Chase',\n",
    "#         'HSCB',\n",
    "#         'Industrial and Commercial Bank of China',\n",
    "#         'Credite Agricole']})\n",
    "\n",
    "# # initialise the name matcher\n",
    "# matcher = NameMatcher(number_of_matches=1, \n",
    "#                       legal_suffixes=True, \n",
    "#                       common_words=False, \n",
    "#                       top_n=50, \n",
    "#                       verbose=True)\n",
    "\n",
    "# # adjust the distance metrics to use\n",
    "# matcher.set_distance_metrics(['bag', 'typo', 'refined_soundex'])\n",
    "\n",
    "# # load the data to which the names should be matched\n",
    "# matcher.load_and_process_master_data(column='Company name',\n",
    "#                                      df_matching_data=df_companies_a, \n",
    "#                                      transform=True)\n",
    "\n",
    "# # perform the name matching on the data you want matched\n",
    "# matches = matcher.match_names(to_be_matched=df_companies_b, \n",
    "#                               column_matching='name')\n",
    "# matches\n",
    "\n",
    "# # combine the datasets based on the matches\n",
    "# # combined = pd.merge(df_companies_a, matches, how='inner', left_index=True, right_on='match_index')\n",
    "# # combined = pd.merge(combined, df_companies_b, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# # combined.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rapidfuzz import fuzz \n",
    "\n",
    "# name1 = \"Kylian Mbappé Lottin\" \n",
    "# name2 = \"Kylian Mbappé\" \n",
    "\n",
    "# similarity_ratio = fuzz.ratio(name1, name2) \n",
    "# print(similarity_ratio) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from rapidfuzz import fuzz \n",
    "\n",
    "# DIRECTORY_FINAL_PLAYERS_CSV_DATAS = \"data/players_skill_dataset/final_players_skill_dataset.csv\"\n",
    "# DIRECTORY_FINAL_PLAYERS_CSV_DATAS_70 = \"data/players_skill_dataset/final_players_skill_dataset_70.csv\"\n",
    "\n",
    "# final_player_df = pd.read_csv(DIRECTORY_FINAL_PLAYERS_CSV_DATAS)\n",
    "# filter_70_final_player_df = pd.DataFrame(columns=final_player_df.columns, index=[0])\n",
    "# for _, row in final_player_df.iterrows():\n",
    "#     name_1 = row[\"player_name\"]\n",
    "#     name_2 = row[\"full_name\"]\n",
    "#     similarity_ratio = fuzz.ratio(name_1, name_2) \n",
    "#     if (similarity_ratio >= 70):\n",
    "#         maps_new_row = {}\n",
    "#         for column in final_player_df.columns:\n",
    "#             maps_new_row[column] = row[column]\n",
    "#         new_row = pd.DataFrame(maps_new_row, index=[0])\n",
    "#         filter_70_final_player_df = pd.concat([new_row, filter_70_final_player_df.loc[:]]).reset_index(drop=True)\n",
    "# filter_70_final_player_df.to_csv(DIRECTORY_FINAL_PLAYERS_CSV_DATAS_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import random as rand\n",
    "\n",
    "# player_ids = [1, 2, 3]\n",
    "# player_skills = [\"acceleration\", \"aggression\", \"agility\", \"balance\", \"ball_control\",\n",
    "#                 \"composure\", \"crossing\", \"curve\", \"dribbling\", \"finishing\",\n",
    "#                 \"freekick_accuracy\", \"heading_accuracy\", \"interceptions\", \"jumping\", \"long_passing\",\n",
    "#                 \"long_shots\", \"marking\", \"penalties\", \"positioning\", \"reactions\",\n",
    "#                 \"shot_power\", \"sliding_tackle\", \"sprint_speed\", \"stamina\", \"short_passing\",\n",
    "#                 \"standing_tackle\", \"strength\", \"vision\", \"volleys\"]\n",
    "# directory_file_csv = 'data/input_decision_making_model/'\n",
    "# filename_csv = 'input_skill_player.csv'\n",
    "\n",
    "# empty_player_skill_df = pd.DataFrame(columns=([\"player_id\"] + player_skills), index=[0])\n",
    "# for player_id in player_ids:\n",
    "#     maps_new_row = {}\n",
    "#     maps_new_row[\"player_id\"] = player_id\n",
    "#     for skill in player_skills:\n",
    "#         maps_new_row[skill] = rand.randint(50, 100)\n",
    "#     new_row = pd.DataFrame(maps_new_row, index=[0])\n",
    "#     empty_player_skill_df = pd.concat([new_row, empty_player_skill_df.loc[:]]).reset_index(drop=True)\n",
    "# empty_player_skill_df.to_csv(directory_file_csv + filename_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import random as rand\n",
    "\n",
    "# player_ids = [1, 2, 3]\n",
    "# player_attributes = [\"height_cm\", \"weight_kgs\", \"age\"]\n",
    "# directory_file_csv = 'data/input_decision_making_model/'\n",
    "# filename_csv = 'input_attribute_player.csv'\n",
    "\n",
    "# empty_player_attribute_df = pd.DataFrame(columns=([\"player_id\"] + player_attributes), index=[0])\n",
    "# for player_id in player_ids:\n",
    "#     maps_new_row = {}\n",
    "#     maps_new_row[\"player_id\"] = player_id\n",
    "#     maps_new_row[\"height_cm\"] = rand.randint(150, 190)\n",
    "#     maps_new_row[\"weight_kgs\"] = rand.randint(50, 80)\n",
    "#     maps_new_row[\"age\"] = rand.randint(18, 40)\n",
    "#     new_row = pd.DataFrame(maps_new_row, index=[0])\n",
    "#     empty_player_attribute_df = pd.concat([new_row, empty_player_attribute_df.loc[:]]).reset_index(drop=True)\n",
    "# empty_player_attribute_df.to_csv(directory_file_csv + filename_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "player_skill_input_csv_start = \"data/input_decision_making_model/real_test/italy_vs_austria_2020_fail_case_skill_player.csv\"\n",
    "player_skill_input_csv_target = \"italy_vs_austria_2020_fail_case_skill_player_lower_20.csv\"\n",
    "player_skills_column = [\n",
    "    \"acceleration\", \"aggression\", \"agility\", \"balance\", \"ball_control\",\n",
    "    \"composure\", \"crossing\", \"curve\", \"dribbling\", \"finishing\",\n",
    "    \"freekick_accuracy\", \"heading_accuracy\", \"interceptions\", \"jumping\", \"long_passing\",\n",
    "    \"long_shots\", \"marking\", \"penalties\", \"positioning\", \"reactions\",\n",
    "    \"shot_power\", \"sliding_tackle\", \"sprint_speed\", \"stamina\", \"short_passing\",\n",
    "    \"standing_tackle\", \"strength\", \"vision\", \"volleys\"\n",
    "]\n",
    "\n",
    "empty_player_skill_target_df = pd.DataFrame(columns=player_skills_column + [\"player_id\"], index=[0])\n",
    "player_skill_input_start_df = pd.read_csv(player_skill_input_csv_start)\n",
    "for _, row in player_skill_input_start_df.iterrows():\n",
    "    maps_new_row = {\"player_id\" : int(row[\"player_id\"])}\n",
    "    for column in player_skills_column:\n",
    "        maps_new_row[column] = row[column] - 20\n",
    "    new_row = pd.DataFrame(maps_new_row, index=[0])\n",
    "    empty_player_skill_target_df = pd.concat([new_row, empty_player_skill_target_df.loc[:]]).reset_index(drop=True)\n",
    "empty_player_skill_target_df.dropna(inplace=True)\n",
    "empty_player_skill_target_df.to_csv(player_skill_input_csv_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
