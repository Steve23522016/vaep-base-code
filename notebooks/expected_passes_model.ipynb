{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from socceraction.data.wyscout import PublicWyscoutLoader\n",
    "from socceraction.spadl.wyscout import convert_to_actions\n",
    "from socceraction.data.opta import OptaLoader\n",
    "from socceraction.data.statsbomb import StatsBombLoader\n",
    "from socceraction.spadl.config import actiontypes, bodyparts\n",
    "import socceraction.spadl as spadl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, brier_score_loss, log_loss, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "from name_matching.name_matcher import NameMatcher\n",
    "from rapidfuzz import fuzz\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_selection import r_regression, SelectKBest, chi2, mutual_info_classif, SequentialFeatureSelector, RFECV, SelectFromModel\n",
    "from scipy.stats import pearsonr, chisquare\n",
    "from mrmr import mrmr_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import Lasso, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG FOR EXPERIMENTS SCENARIO\n",
    "INCLUDE_SKILL_PLAYERS_OPTIONS = [\n",
    "    False,\n",
    "    True\n",
    "]\n",
    "SAMPLING_OPTIONS = [\n",
    "    \"none\",\n",
    "    \"random_oversampled\",\n",
    "    \"random_undersampled\",\n",
    "    \"smote_oversampled\"\n",
    "]\n",
    "FEATURE_SELECTION_OPTIONS = [\n",
    "    \"chisquare\",\n",
    "    \"mutualinf\",\n",
    "    \"mrmr\",\n",
    "    \"rfembedded\",\n",
    "    \"lasso\"\n",
    "]\n",
    "MODEL_ALGORITHM_OPTIONS = [\n",
    "    \"xgbregressor\",\n",
    "    \"rfregressor\",\n",
    "    \"logregression\"\n",
    "]\n",
    "CONFIG_EXPERIMENTS_SCENARIO_MAP = {}\n",
    "\n",
    "def construct_config_experiments_scenario_map():\n",
    "    index_counter = 1\n",
    "    for include_skill_opt in INCLUDE_SKILL_PLAYERS_OPTIONS:\n",
    "        for sampling_opt in SAMPLING_OPTIONS:\n",
    "            if (include_skill_opt == False):\n",
    "                for algorithm_opt in MODEL_ALGORITHM_OPTIONS:\n",
    "                    CONFIG_EXPERIMENTS_SCENARIO_MAP[index_counter] = \\\n",
    "                        {\"include_skill_opt\" : 1 if include_skill_opt else 0, \\\n",
    "                        \"sampling_opt\" : sampling_opt, \\\n",
    "                        \"feature_selection_opt\" : \"none\", \\\n",
    "                        \"algorithm_opt\" : algorithm_opt}\n",
    "                    index_counter += 1\n",
    "            else:\n",
    "                for feature_selection_opt in FEATURE_SELECTION_OPTIONS:\n",
    "                    for algorithm_opt in MODEL_ALGORITHM_OPTIONS:\n",
    "                        CONFIG_EXPERIMENTS_SCENARIO_MAP[index_counter] = \\\n",
    "                            {\"include_skill_opt\" : 1 if include_skill_opt else 0, \\\n",
    "                            \"sampling_opt\" : sampling_opt, \\\n",
    "                            \"feature_selection_opt\" : feature_selection_opt, \\\n",
    "                            \"algorithm_opt\" : algorithm_opt}\n",
    "                        index_counter += 1\n",
    "\n",
    "construct_config_experiments_scenario_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS FOR TEST EXPERIMENT RESULT\n",
    "COLUMNS_EVALUATION_METRIC = [\n",
    "    \"mean_squared_error_score\",\n",
    "    \"root_mean_squared_error_score\",\n",
    "    \"auc_score\",\n",
    "    \"brier_score\",\n",
    "    \"log_loss_score\",\n",
    "    \"mean_absolute_error_score\",\n",
    "    \"r_squared_score\",\n",
    "    \"mean_absolute_percentage_error_score\"\n",
    "]\n",
    "COLUMNS_SCENARIO_NAME = [\n",
    "    \"include_skill_opt\",\n",
    "    \"sampling_opt\",\n",
    "    \"feature_selection_opt\",\n",
    "    \"algorithm_opt\"\n",
    "]\n",
    "COLUMNS_EXPERIMENT_RESULT = [\"case_number\"] + COLUMNS_SCENARIO_NAME + COLUMNS_EVALUATION_METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wyscout = PublicWyscoutLoader(root=\"data/wyscout\")\n",
    "api_opta = OptaLoader(root=\"data/opta\")\n",
    "# api_statsbomb = StatsBombLoader(root=\"data/statsbomb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_id : 0   action_name : pass\n",
      "action_id : 1   action_name : cross\n",
      "action_id : 2   action_name : throw_in\n",
      "action_id : 3   action_name : freekick_crossed\n",
      "action_id : 4   action_name : freekick_short\n",
      "action_id : 5   action_name : corner_crossed\n",
      "action_id : 6   action_name : corner_short\n",
      "action_id : 7   action_name : take_on\n",
      "action_id : 8   action_name : foul\n",
      "action_id : 9   action_name : tackle\n",
      "action_id : 10   action_name : interception\n",
      "action_id : 11   action_name : shot\n",
      "action_id : 12   action_name : shot_penalty\n",
      "action_id : 13   action_name : shot_freekick\n",
      "action_id : 14   action_name : keeper_save\n",
      "action_id : 15   action_name : keeper_claim\n",
      "action_id : 16   action_name : keeper_punch\n",
      "action_id : 17   action_name : keeper_pick_up\n",
      "action_id : 18   action_name : clearance\n",
      "action_id : 19   action_name : bad_touch\n",
      "action_id : 20   action_name : non_action\n",
      "action_id : 21   action_name : dribble\n",
      "action_id : 22   action_name : goalkick\n"
     ]
    }
   ],
   "source": [
    "for idx, action_name in enumerate(actiontypes):\n",
    "    print(f'action_id : {idx}   action_name : {action_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bodypart_id : 0   bodypart_name : foot\n",
      "bodypart_id : 1   bodypart_name : head\n",
      "bodypart_id : 2   bodypart_name : other\n",
      "bodypart_id : 3   bodypart_name : head/other\n",
      "bodypart_id : 4   bodypart_name : foot_left\n",
      "bodypart_id : 5   bodypart_name : foot_right\n"
     ]
    }
   ],
   "source": [
    "for idx, bodypart_name in enumerate(bodyparts):\n",
    "    print(f'bodypart_id : {idx}   bodypart_name : {bodypart_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_events_df_to_spadl(events_df, home_team_id):\n",
    "    spadl_events_df = convert_to_actions(events_df, home_team_id)\n",
    "    spadl_events_df['time_seconds'] = spadl_events_df['time_seconds'].astype('float64')\n",
    "    spadl_events_df['timestamp'] = pd.to_datetime(spadl_events_df['time_seconds'], unit='s')\n",
    "    spadl_events_df = spadl.play_left_to_right(spadl_events_df, home_team_id)\n",
    "    return spadl_events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO ADD ADDITIONAL INFO IN RAW SPADL DATAFRAME\n",
    "STANDARD_LENGTH_COURT = 105\n",
    "STANDARD_WIDTH_COURT = 68\n",
    "STANDARD_GOALLINE_WIDTH = 7.32\n",
    "\n",
    "# Helper Functions\n",
    "def calculate_distance_pass(coordinate_x, coordinate_y, end_x, end_y):\n",
    "    distance_passing = math.sqrt((abs(end_x - coordinate_x)) ** 2 + (abs(end_y - coordinate_y)) ** 2)\n",
    "    return distance_passing\n",
    "\n",
    "def calculate_distance_pass_apply_df(row):\n",
    "    return calculate_distance_pass(row['start_x'], row['start_y'], row['end_x'], row['end_y'])\n",
    "\n",
    "def filter_out_is_home_team_apply_df(row, home_team_id):\n",
    "    return 1 if row['team_id'] == home_team_id else 0\n",
    "\n",
    "# Add distance passing column\n",
    "def add_distance_pass_to_spadl_df(spadl_df):\n",
    "    spadl_df['distance_pass'] = spadl_df.apply(calculate_distance_pass_apply_df, axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Add is_home_team column (boolean 0/1)\n",
    "def add_is_home_team_column_to_spadl_df(spadl_df, home_team_id):\n",
    "    spadl_df['is_home_team'] = spadl_df.apply(lambda x : filter_out_is_home_team_apply_df(x, home_team_id), axis=1)\n",
    "    return spadl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all dataset action specific type, export them to csv files\n",
    "# Pass (action_id = 0), Cross (action_id = 1)\n",
    "PASS_ACTION_ID = [0,1] \n",
    "\n",
    "def collect_raw_pass_spadl_df(source=\"Wyscout\", period=1):\n",
    "    api = api_wyscout\n",
    "    list_competitions_ids = []\n",
    "    list_game_ids = []\n",
    "\n",
    "    competitions_df = api.competitions()\n",
    "    for _, row in competitions_df.iterrows():\n",
    "        list_competitions_ids.append((row['competition_id'], row['season_id']))\n",
    "        \n",
    "    for competition_id, season_id in list_competitions_ids:\n",
    "        games_df = api.games(competition_id, season_id)\n",
    "        for _, row in games_df.iterrows():\n",
    "            list_game_ids.append((row['game_id'], row['home_team_id'], row['away_team_id']))\n",
    "            \n",
    "    for game_id, home_team_id, away_team_id in list_game_ids:\n",
    "        this_game_events_df = api.events(game_id)\n",
    "        this_game_events_spadl_df = convert_events_df_to_spadl(this_game_events_df, home_team_id)\n",
    "        this_game_events_spadl_df = this_game_events_spadl_df[this_game_events_spadl_df['type_id'].isin(PASS_ACTION_ID)]\n",
    "        if (period != None):\n",
    "            this_game_events_spadl_df = this_game_events_spadl_df[this_game_events_spadl_df['period_id'] == period]\n",
    "        else:\n",
    "            this_game_events_spadl_df = this_game_events_spadl_df[this_game_events_spadl_df['period_id'] == 1]\n",
    "        # Add additional computed column to support xG model\n",
    "        this_game_events_spadl_df = add_is_home_team_column_to_spadl_df(this_game_events_spadl_df, home_team_id)\n",
    "        this_game_events_spadl_df = add_distance_pass_to_spadl_df(this_game_events_spadl_df)\n",
    "\n",
    "        # Export to external csv iteratively\n",
    "        this_game_events_spadl_df.to_csv(f'data/training_data_xpass_wyscout/{game_id}_{home_team_id}_{away_team_id}_xpass_data.csv')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DRIVER (comment it if csv files already loaded)\n",
    "# collect_raw_pass_spadl_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv datas already retrieved then concat them into one big dataframe\n",
    "import os\n",
    "\n",
    "DIRECTORY_XPASS_CSV_DATAS = \"data/training_data_xpass_wyscout\"\n",
    "\n",
    "def load_and_concat_xpass_df_from_csv():\n",
    "    list_pass_event_df = []\n",
    "    for filename in os.listdir(DIRECTORY_XPASS_CSV_DATAS):\n",
    "        f = os.path.join(DIRECTORY_XPASS_CSV_DATAS, filename)\n",
    "        if os.path.isfile(f):\n",
    "            pass_event_df = pd.read_csv(f)\n",
    "            list_pass_event_df.append(pass_event_df)\n",
    "    return pd.concat(list_pass_event_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>game_id_x</th>\n",
       "      <th>period_id</th>\n",
       "      <th>time_seconds</th>\n",
       "      <th>team_id_x</th>\n",
       "      <th>player_id</th>\n",
       "      <th>start_x</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>end_y</th>\n",
       "      <th>...</th>\n",
       "      <th>LWB</th>\n",
       "      <th>LDM</th>\n",
       "      <th>CDM</th>\n",
       "      <th>RDM</th>\n",
       "      <th>RWB</th>\n",
       "      <th>LB</th>\n",
       "      <th>LCB</th>\n",
       "      <th>CB</th>\n",
       "      <th>RCB</th>\n",
       "      <th>RB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1694390</td>\n",
       "      <td>1</td>\n",
       "      <td>1.255990</td>\n",
       "      <td>4418</td>\n",
       "      <td>26010</td>\n",
       "      <td>52.50</td>\n",
       "      <td>35.36</td>\n",
       "      <td>49.35</td>\n",
       "      <td>34.00</td>\n",
       "      <td>...</td>\n",
       "      <td>55+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>55+3</td>\n",
       "      <td>52+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>52+3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>1694390</td>\n",
       "      <td>1</td>\n",
       "      <td>375.411598</td>\n",
       "      <td>4418</td>\n",
       "      <td>26010</td>\n",
       "      <td>32.55</td>\n",
       "      <td>32.64</td>\n",
       "      <td>31.50</td>\n",
       "      <td>50.32</td>\n",
       "      <td>...</td>\n",
       "      <td>55+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>55+3</td>\n",
       "      <td>52+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>52+3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174</td>\n",
       "      <td>1694390</td>\n",
       "      <td>1</td>\n",
       "      <td>709.435262</td>\n",
       "      <td>4418</td>\n",
       "      <td>26010</td>\n",
       "      <td>65.10</td>\n",
       "      <td>51.68</td>\n",
       "      <td>80.85</td>\n",
       "      <td>62.56</td>\n",
       "      <td>...</td>\n",
       "      <td>55+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>55+3</td>\n",
       "      <td>52+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>52+3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>1694390</td>\n",
       "      <td>1</td>\n",
       "      <td>1292.384871</td>\n",
       "      <td>4418</td>\n",
       "      <td>26010</td>\n",
       "      <td>69.30</td>\n",
       "      <td>51.68</td>\n",
       "      <td>56.70</td>\n",
       "      <td>52.36</td>\n",
       "      <td>...</td>\n",
       "      <td>55+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>55+3</td>\n",
       "      <td>52+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>52+3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>349</td>\n",
       "      <td>1694390</td>\n",
       "      <td>1</td>\n",
       "      <td>1430.028706</td>\n",
       "      <td>4418</td>\n",
       "      <td>26010</td>\n",
       "      <td>65.10</td>\n",
       "      <td>62.56</td>\n",
       "      <td>47.25</td>\n",
       "      <td>55.76</td>\n",
       "      <td>...</td>\n",
       "      <td>55+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>59+3</td>\n",
       "      <td>55+3</td>\n",
       "      <td>52+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>56+3</td>\n",
       "      <td>52+3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x  game_id_x  period_id  time_seconds  team_id_x  player_id  \\\n",
       "0             0    1694390          1      1.255990       4418      26010   \n",
       "1            72    1694390          1    375.411598       4418      26010   \n",
       "2           174    1694390          1    709.435262       4418      26010   \n",
       "3           315    1694390          1   1292.384871       4418      26010   \n",
       "4           349    1694390          1   1430.028706       4418      26010   \n",
       "\n",
       "   start_x  start_y  end_x  end_y  ...   LWB   LDM   CDM   RDM   RWB    LB  \\\n",
       "0    52.50    35.36  49.35  34.00  ...  55+3  59+3  59+3  59+3  55+3  52+3   \n",
       "1    32.55    32.64  31.50  50.32  ...  55+3  59+3  59+3  59+3  55+3  52+3   \n",
       "2    65.10    51.68  80.85  62.56  ...  55+3  59+3  59+3  59+3  55+3  52+3   \n",
       "3    69.30    51.68  56.70  52.36  ...  55+3  59+3  59+3  59+3  55+3  52+3   \n",
       "4    65.10    62.56  47.25  55.76  ...  55+3  59+3  59+3  59+3  55+3  52+3   \n",
       "\n",
       "    LCB    CB   RCB    RB  \n",
       "0  56+3  56+3  56+3  52+3  \n",
       "1  56+3  56+3  56+3  52+3  \n",
       "2  56+3  56+3  56+3  52+3  \n",
       "3  56+3  56+3  56+3  52+3  \n",
       "4  56+3  56+3  56+3  52+3  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JOIN ALREADY CONSTRUCTED PLAYER SKILLS DATASET WITH ORIGIN EVENT DATASET WYSCOUT\n",
    "DIRECTORY_FINAL_PLAYERS_CSV_DATAS = \"data/players_skill_dataset/final_players_skill_dataset.csv\"\n",
    "\n",
    "player_skills_dataset = pd.read_csv(DIRECTORY_FINAL_PLAYERS_CSV_DATAS)\n",
    "big_dataframe_xpass_model = load_and_concat_xpass_df_from_csv()\n",
    "big_dataframe_xpass_model = big_dataframe_xpass_model.merge(player_skills_dataset, how='inner',on='player_id')\n",
    "big_dataframe_xpass_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_x</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>end_y</th>\n",
       "      <th>result_id</th>\n",
       "      <th>is_home_team</th>\n",
       "      <th>distance_pass</th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kgs</th>\n",
       "      <th>...</th>\n",
       "      <th>long_shots</th>\n",
       "      <th>aggression</th>\n",
       "      <th>interceptions</th>\n",
       "      <th>positioning</th>\n",
       "      <th>vision</th>\n",
       "      <th>penalties</th>\n",
       "      <th>composure</th>\n",
       "      <th>marking</th>\n",
       "      <th>standing_tackle</th>\n",
       "      <th>sliding_tackle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.50</td>\n",
       "      <td>35.36</td>\n",
       "      <td>49.35</td>\n",
       "      <td>34.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.431049</td>\n",
       "      <td>32.0</td>\n",
       "      <td>193.04</td>\n",
       "      <td>92.1</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.55</td>\n",
       "      <td>32.64</td>\n",
       "      <td>31.50</td>\n",
       "      <td>50.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.711152</td>\n",
       "      <td>32.0</td>\n",
       "      <td>193.04</td>\n",
       "      <td>92.1</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.10</td>\n",
       "      <td>51.68</td>\n",
       "      <td>80.85</td>\n",
       "      <td>62.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.142542</td>\n",
       "      <td>32.0</td>\n",
       "      <td>193.04</td>\n",
       "      <td>92.1</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.30</td>\n",
       "      <td>51.68</td>\n",
       "      <td>56.70</td>\n",
       "      <td>52.36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.618336</td>\n",
       "      <td>32.0</td>\n",
       "      <td>193.04</td>\n",
       "      <td>92.1</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.10</td>\n",
       "      <td>62.56</td>\n",
       "      <td>47.25</td>\n",
       "      <td>55.76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.101374</td>\n",
       "      <td>32.0</td>\n",
       "      <td>193.04</td>\n",
       "      <td>92.1</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_x  start_y  end_x  end_y  result_id  is_home_team  distance_pass  \\\n",
       "0    52.50    35.36  49.35  34.00          1             1       3.431049   \n",
       "1    32.55    32.64  31.50  50.32          1             1      17.711152   \n",
       "2    65.10    51.68  80.85  62.56          1             1      19.142542   \n",
       "3    69.30    51.68  56.70  52.36          0             1      12.618336   \n",
       "4    65.10    62.56  47.25  55.76          0             1      19.101374   \n",
       "\n",
       "    age  height_cm  weight_kgs  ...  long_shots  aggression  interceptions  \\\n",
       "0  32.0     193.04        92.1  ...        74.0        76.0           42.0   \n",
       "1  32.0     193.04        92.1  ...        74.0        76.0           42.0   \n",
       "2  32.0     193.04        92.1  ...        74.0        76.0           42.0   \n",
       "3  32.0     193.04        92.1  ...        74.0        76.0           42.0   \n",
       "4  32.0     193.04        92.1  ...        74.0        76.0           42.0   \n",
       "\n",
       "   positioning  vision  penalties  composure  marking  standing_tackle  \\\n",
       "0         83.0    77.0       83.0       79.0     37.0             37.0   \n",
       "1         83.0    77.0       83.0       79.0     37.0             37.0   \n",
       "2         83.0    77.0       83.0       79.0     37.0             37.0   \n",
       "3         83.0    77.0       83.0       79.0     37.0             37.0   \n",
       "4         83.0    77.0       83.0       79.0     37.0             37.0   \n",
       "\n",
       "   sliding_tackle  \n",
       "0            20.0  \n",
       "1            20.0  \n",
       "2            20.0  \n",
       "3            20.0  \n",
       "4            20.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT ONLY FEATURED COLUMN FROM BIG DATASETS\n",
    "features_column_included = [\"start_x\", \"start_y\", \"end_x\", \"end_y\", \"distance_pass\", \"is_home_team\", \"result_id\"]\n",
    "player_skills_column_included = [\"acceleration\", \"aggression\", \"agility\", \"balance\", \"ball_control\",\n",
    "                                 \"composure\", \"crossing\", \"curve\", \"dribbling\", \"finishing\",\n",
    "                                 \"freekick_accuracy\", \"heading_accuracy\", \"interceptions\", \"jumping\", \"long_passing\",\n",
    "                                 \"long_shots\", \"marking\", \"penalties\", \"positioning\", \"reactions\",\n",
    "                                 \"shot_power\", \"sliding_tackle\", \"sprint_speed\", \"stamina\", \"short_passing\",\n",
    "                                 \"standing_tackle\", \"strength\", \"vision\", \"volleys\"]\n",
    "player_attribute_column_included = [\"height_cm\", \"weight_kgs\", \"age\"]\n",
    "\n",
    "big_dataframe_xpass_model = big_dataframe_xpass_model[[c for c in big_dataframe_xpass_model.columns if c in (features_column_included + player_skills_column_included + player_attribute_column_included)]]\n",
    "big_dataframe_xpass_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 1 : Random Oversample Function\n",
    "def training_data_random_oversampled(X_train, Y_train):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    X_resampled, Y_resampled = ros.fit_resample(X_train, Y_train)\n",
    "    return (X_resampled, Y_resampled)\n",
    "\n",
    "# CASE 2 : Random Undersample Function\n",
    "def training_data_random_undersampled(X_train, Y_train):\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    X_resampled, Y_resampled = rus.fit_resample(X_train, Y_train)\n",
    "    return (X_resampled, Y_resampled)\n",
    "\n",
    "# CASE 3 : Random SMOTE Oversample Function\n",
    "def training_data_smote_oversampled(X_train, Y_train):\n",
    "    X_resampled, Y_resampled = SMOTE().fit_resample(X_train, Y_train)\n",
    "    return (X_resampled, Y_resampled)\n",
    "\n",
    "# X CASE 1 : Feature Selection - Pearson Coefficient\n",
    "def filter_columns_feature_selection_pearson(X_train, Y_train, columns_considered, threshold):\n",
    "    new_columns_after_selection = []\n",
    "    for _, skill in enumerate(columns_considered):\n",
    "        correlation_value, _ = pearsonr(X_train[skill], Y_train)\n",
    "        if correlation_value >= threshold:\n",
    "            new_columns_after_selection.append(skill)\n",
    "    return new_columns_after_selection\n",
    "\n",
    "def training_data_feature_selection_pearson(X_train, Y_train, columns_considered, threshold):\n",
    "    columns_filtered = filter_columns_feature_selection_pearson(X_train, Y_train, columns_considered, threshold)\n",
    "    print(columns_filtered)\n",
    "    return (X_train[columns_filtered], Y_train)\n",
    "\n",
    "# V CASE 2 : Feature Selection - Chi Square\n",
    "def filter_columns_feature_selection_chisquare(X_train, Y_train, columns_considered, num_of_features):\n",
    "    chi2_selector = SelectKBest(chi2, k=num_of_features) \n",
    "    df_feature = X_train[columns_considered]\n",
    "    chi2_selector.fit(df_feature, Y_train)\n",
    "    cols = chi2_selector.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_chisquare(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_filtered = filter_columns_feature_selection_chisquare(X_train, Y_train, columns_considered, num_of_features)\n",
    "    print(columns_filtered)\n",
    "    return (X_train[columns_filtered], Y_train)\n",
    "\n",
    "# V CASE 3 : Feature Selection - Mutual Information\n",
    "def filter_columns_feature_selection_mutualinf(X_train, Y_train, columns_considered, num_of_features):\n",
    "    mi_selector = SelectKBest(mutual_info_classif, k=num_of_features) \n",
    "    df_feature = X_train[columns_considered]\n",
    "    mi_selector.fit(df_feature, Y_train)\n",
    "    cols = mi_selector.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_mutualinf(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_filtered = filter_columns_feature_selection_mutualinf(X_train, Y_train, columns_considered, num_of_features)\n",
    "    print(columns_filtered)\n",
    "    return (X_train[columns_filtered], Y_train)\n",
    "\n",
    "# V CASE 4 : Feature Selection - mRMR Selection\n",
    "def filter_columns_feature_selection_mrmr(X_train, Y_train, columns_considered, num_of_features):\n",
    "    df_feature = X_train[columns_considered]\n",
    "    selected_features = mrmr_classif(X=df_feature, y=Y_train, K=num_of_features)\n",
    "    return selected_features\n",
    "\n",
    "def training_data_feature_selection_mrmr(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_filtered = filter_columns_feature_selection_mrmr(X_train, Y_train, columns_considered, num_of_features)\n",
    "    print(columns_filtered)\n",
    "    return (X_train[columns_filtered], Y_train)\n",
    "\n",
    "# X CASE 5 : Feature Selection - Sequential Forward Selection (SFS)\n",
    "def filter_columns_feature_selection_sfs(X_train, Y_train, columns_considered, num_of_features):\n",
    "    rf = RandomForestClassifier()\n",
    "    sfs = SequentialFeatureSelector(rf, n_features_to_select=num_of_features, direction='forward')\n",
    "    df_feature = X_train[columns_considered]\n",
    "    sfs.fit(df_feature, Y_train)\n",
    "    cols = sfs.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_sfs(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_filtered = filter_columns_feature_selection_sfs(X_train, Y_train, columns_considered, num_of_features)\n",
    "    print(columns_filtered)\n",
    "    return (X_train[columns_filtered], Y_train)\n",
    "\n",
    "# X CASE 6 : Feature Selection - Sequential Backward Elimination (SBE)\n",
    "def filter_columns_feature_selection_sbe(X_train, Y_train, columns_considered, num_of_features):\n",
    "    rf = RandomForestClassifier()\n",
    "    sfs = SequentialFeatureSelector(rf, n_features_to_select=num_of_features, direction='backward')\n",
    "    df_feature = X_train[columns_considered]\n",
    "    sfs.fit(df_feature, Y_train)\n",
    "    cols = sfs.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_sbe(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_filtered = filter_columns_feature_selection_sbe(X_train, Y_train, columns_considered, num_of_features)\n",
    "    print(columns_filtered)\n",
    "    return (X_train[columns_filtered], Y_train)\n",
    "\n",
    "# X CASE 7 : Feature Selection - Recursive Feature Elimination\n",
    "def filter_columns_feature_selection_rfe(X_train, Y_train, columns_considered, num_of_features):\n",
    "    estimator = LinearSVR()\n",
    "    selector = RFECV(estimator, step=1, cv=num_of_features)\n",
    "    df_feature = X_train[columns_considered]\n",
    "    selector.fit(df_feature, Y_train)\n",
    "    cols = selector.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_rfe(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_filtered = filter_columns_feature_selection_rfe(X_train, Y_train, columns_considered, num_of_features)\n",
    "    print(columns_filtered)\n",
    "    return (X_train[columns_filtered], Y_train)\n",
    "\n",
    "# V CASE 8 : Feature Selection - Random Forest Embedded (rfembedded)\n",
    "def filter_columns_feature_selection_rfembedded(X_train, Y_train, columns_considered, num_of_features):\n",
    "    estimator = RandomForestClassifier()\n",
    "    selector = SelectFromModel(estimator=estimator, max_features=num_of_features)\n",
    "    df_feature = X_train[columns_considered]\n",
    "    selector.fit(df_feature, Y_train)\n",
    "    cols = selector.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_rfembedded(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_filtered = filter_columns_feature_selection_rfembedded(X_train, Y_train, columns_considered, num_of_features)\n",
    "    print(columns_filtered)\n",
    "    return (X_train[columns_filtered], Y_train)\n",
    "\n",
    "# V CASE 9 : Feature Selection - LASSO\n",
    "def filter_columns_feature_selection_lasso(X_train, Y_train, columns_considered, num_of_features):\n",
    "    estimator = LogisticRegression(penalty='l2', C=0.5, solver='newton-cholesky')\n",
    "    selector = SelectFromModel(estimator=estimator, max_features=num_of_features)\n",
    "    df_feature = X_train[columns_considered]\n",
    "    selector.fit(df_feature, Y_train)\n",
    "    cols = selector.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_lasso(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_filtered = filter_columns_feature_selection_lasso(X_train, Y_train, columns_considered, num_of_features)\n",
    "    print(columns_filtered)\n",
    "    return (X_train[columns_filtered], Y_train)\n",
    "\n",
    "# CASE 1 : Train with model XGBRegressor\n",
    "def fit_and_train_with_model_xgbregressor(X_train, Y_train):\n",
    "    model = XGBRegressor(objective=\"reg:logistic\")\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model\n",
    "\n",
    "# CASE 2 : Train with model RandomForestRegressor\n",
    "def fit_and_train_with_model_rfregressor(X_train, Y_train):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model\n",
    "\n",
    "# CASE 3 : Train with model LogisticRegression\n",
    "def fit_and_train_with_model_logregression(X_train, Y_train):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    652657\n",
      "0    139205\n",
      "2      3075\n",
      "Name: result_id, dtype: int64\n",
      "1.0    652657\n",
      "0.0    139205\n",
      "Name: result_id, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m X_train_split, X_test_split, y_train_split, y_test_split \u001b[38;5;241m=\u001b[39m train_test_split(X_feature_sel, Y_feature_sel, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# 9. Train Model\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_and_train_with_model_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malgorithm_opt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_split\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# 10. Predict Testing Data\u001b[39;00m\n\u001b[0;32m     56\u001b[0m y_predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_split)\n",
      "Cell \u001b[1;32mIn[14], line 155\u001b[0m, in \u001b[0;36mfit_and_train_with_model_rfregressor\u001b[1;34m(X_train, Y_train)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_and_train_with_model_rfregressor\u001b[39m(X_train, Y_train):\n\u001b[0;32m    154\u001b[0m     model \u001b[38;5;241m=\u001b[39m RandomForestRegressor()\n\u001b[1;32m--> 155\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# FEATURE PREPROCESSING BIG DATASETS AND CREATE XGBOOST MODEL\n",
    "# 1. Change all numeric columns with MinMaxScaler\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "columns_minmax_scaler = player_skills_column_included + player_attribute_column_included + [\"start_x\", \"start_y\", \"end_x\", \"end_y\", \"distance_pass\"]\n",
    "big_dataframe_xpass_model[columns_minmax_scaler] = scaler.fit_transform(big_dataframe_xpass_model[columns_minmax_scaler])\n",
    "\n",
    "# 2. Check if data is unbalanced. If it is unbalanced, then do method to oversize the sample\n",
    "print(big_dataframe_xpass_model['result_id'].value_counts())\n",
    "\n",
    "# 3. Change result_id label into float64 type\n",
    "big_dataframe_xpass_model['result_id'] = big_dataframe_xpass_model['result_id'].astype('float64')\n",
    "\n",
    "# 4. Remove dataframe instead of having result_id (0,1) --> (fail, success)\n",
    "big_dataframe_xpass_model = big_dataframe_xpass_model[big_dataframe_xpass_model['result_id'].isin([0,1])]\n",
    "print(big_dataframe_xpass_model['result_id'].value_counts())\n",
    "\n",
    "# 5. Split train data and test data from Big Datasets\n",
    "all_feature_columns = columns_minmax_scaler + [\"is_home_team\"]\n",
    "X_train = big_dataframe_xpass_model[all_feature_columns]\n",
    "Y_train = big_dataframe_xpass_model[\"result_id\"]\n",
    "\n",
    "# Empty dataframe for saving test result\n",
    "empty_test_result = pd.DataFrame(columns=COLUMNS_EXPERIMENT_RESULT, index=[0])\n",
    "\n",
    "for case_number in sorted(list(CONFIG_EXPERIMENTS_SCENARIO_MAP.keys())):\n",
    "    include_skill_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"include_skill_opt\"]\n",
    "    sampling_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"sampling_opt\"]\n",
    "    feature_selection_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"feature_selection_opt\"]\n",
    "    algorithm_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"algorithm_opt\"]\n",
    "\n",
    "    # 6. Filter out all player skills and attributes column if not include skill option\n",
    "    if include_skill_opt == 0:\n",
    "        only_featured_column = [column for column in features_column_included if column != 'result_id']\n",
    "        X_train_filtered = X_train[only_featured_column]\n",
    "    else:\n",
    "        X_train_filtered = X_train\n",
    "\n",
    "    # 7. Do oversampling/undersampling and feature selection at same time\n",
    "    if sampling_opt == \"none\":\n",
    "        X_resampled, Y_resampled = X_train_filtered, Y_train\n",
    "    else:\n",
    "        X_resampled, Y_resampled = globals()[\"training_data_\" + sampling_opt](X_train_filtered, Y_train)\n",
    "    if feature_selection_opt == \"none\":\n",
    "        X_feature_sel, Y_feature_sel = X_resampled, Y_resampled\n",
    "    else:\n",
    "        X_feature_sel, Y_feature_sel = globals()[\"training_data_feature_selection_\" + feature_selection_opt](X_resampled, Y_resampled, player_skills_column_included, 10)\n",
    "\n",
    "    # 8. Do train_test_split on training data\n",
    "    X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_feature_sel, Y_feature_sel, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 9. Train Model\n",
    "    model = globals()[\"fit_and_train_with_model_\" + algorithm_opt](X_train_split, y_train_split)\n",
    "\n",
    "    # 10. Predict Testing Data\n",
    "    y_predict = model.predict(X_test_split)\n",
    "\n",
    "    # 11. Save test result experiment\n",
    "    mean_squared_error_score = mean_squared_error(y_test_split, y_predict)\n",
    "    root_mean_squared_error_score = mean_squared_error(y_test_split, y_predict, squared=False)\n",
    "    auc_score = roc_auc_score(y_test_split, y_predict)\n",
    "    brier_score = brier_score_loss(y_test_split, y_predict)\n",
    "    log_loss_score = log_loss(y_test_split, y_predict)\n",
    "    mean_absolute_error_score = mean_absolute_error(y_test_split, y_predict)\n",
    "    r_squared_score = r2_score(y_test_split, y_predict)\n",
    "    mean_absolute_percentage_error_score = mean_absolute_percentage_error(y_test_split, y_predict)\n",
    "\n",
    "    maps_new_row = {}\n",
    "    for column in COLUMNS_EXPERIMENT_RESULT:\n",
    "        if column not in COLUMNS_EVALUATION_METRIC:\n",
    "            if column == \"case_number\":\n",
    "                maps_new_row[\"case_number\"] = case_number\n",
    "            elif column in COLUMNS_SCENARIO_NAME:\n",
    "                maps_new_row[column] = globals()[column]\n",
    "        else:\n",
    "            maps_new_row[column] = globals()[column]     \n",
    "    new_row = pd.DataFrame(maps_new_row, index=[0])\n",
    "    empty_test_result = pd.concat([new_row, empty_test_result.loc[:]]).reset_index(drop=True)\n",
    "\n",
    "    # 12. Save model to external file\n",
    "    filename = f'xpass_model_case_{case_number}.sav'\n",
    "    directory_model = \"data/model_xpass_wyscout/\"\n",
    "    pickle.dump(model, open(directory_model + filename, 'wb'))\n",
    "\n",
    "# 13. Save test result experiment to external file\n",
    "filename = 'xpass_test_model_experiment_result.csv'\n",
    "directory_model = \"data/model_xpass_wyscout/\"\n",
    "empty_test_result.to_csv(directory_model + filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
