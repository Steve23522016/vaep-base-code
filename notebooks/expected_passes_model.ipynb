{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from socceraction.data.wyscout import PublicWyscoutLoader\n",
    "from socceraction.spadl.wyscout import convert_to_actions as convert_to_actions_wyscout\n",
    "from socceraction.spadl.statsbomb import convert_to_actions as convert_to_actions_statsbomb\n",
    "from socceraction.data.opta import OptaLoader\n",
    "from socceraction.data.statsbomb import StatsBombLoader\n",
    "from socceraction.spadl.config import actiontypes, bodyparts\n",
    "import socceraction.spadl as spadl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, brier_score_loss, log_loss, mean_absolute_error, r2_score, mean_absolute_percentage_error, silhouette_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, balanced_accuracy_score\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "from name_matching.name_matcher import NameMatcher\n",
    "from rapidfuzz import fuzz\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_selection import r_regression, SelectKBest, chi2, mutual_info_classif, SequentialFeatureSelector, RFECV, SelectFromModel, mutual_info_regression, f_regression\n",
    "from scipy.stats import pearsonr, chisquare\n",
    "from mrmr import mrmr_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR, SVC\n",
    "from sklearn.linear_model import Lasso, LogisticRegression, LinearRegression\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "from functools import partial\n",
    "from numpy import argmax\n",
    "from sklearn import metrics\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG FOR EXPERIMENTS SCENARIO\n",
    "USE_EVALUATION_METRIC_CLASSIFICATION = False\n",
    "INCLUDE_SKILL_PLAYERS_OPTIONS = [\n",
    "    False,\n",
    "    # True\n",
    "]\n",
    "SAMPLING_OPTIONS = [\n",
    "    # \"none\",\n",
    "    \"random_oversampled\",\n",
    "    \"random_undersampled\",\n",
    "    \"smote_oversampled\"\n",
    "]\n",
    "FEATURE_SELECTION_OPTIONS = [\n",
    "    \"pearson\",\n",
    "    \"chisquare\",\n",
    "    \"mutualinf\",\n",
    "    \"mrmr\",\n",
    "    \"rfembedded\",\n",
    "    \"lasso\"\n",
    "]\n",
    "RANDOM_STATE_OPTIONS = [0, 42]\n",
    "FEATURE_SELECTION_OPTIONS_FOR_PLAYER_PROBS = [\n",
    "    \"pearson\",\n",
    "    \"mutualinf\"\n",
    "]\n",
    "if USE_EVALUATION_METRIC_CLASSIFICATION:\n",
    "    MODEL_ALGORITHM_OPTIONS = [\n",
    "        \"xgbclassifier\",\n",
    "        # \"catboostclassifier\",\n",
    "        # \"rfclassifier\"\n",
    "    ]\n",
    "else:\n",
    "    MODEL_ALGORITHM_OPTIONS = [\n",
    "        # \"xgbregressor\",\n",
    "        # \"rfregressor\",\n",
    "        \"logregression\"\n",
    "    ]\n",
    "CONFIG_EXPERIMENTS_SCENARIO_MAP = {}\n",
    "CONFIG_EXPERIMENTS_SKILL_PROBS_SCENARIO_MAP = {}\n",
    "\n",
    "def construct_config_experiments_scenario_map():\n",
    "    index_counter = 1\n",
    "    for include_skill_opt in INCLUDE_SKILL_PLAYERS_OPTIONS:\n",
    "        for random_state_opt in RANDOM_STATE_OPTIONS:\n",
    "            for sampling_opt in SAMPLING_OPTIONS:\n",
    "                if (include_skill_opt == False):\n",
    "                    for algorithm_opt in MODEL_ALGORITHM_OPTIONS:\n",
    "                        CONFIG_EXPERIMENTS_SCENARIO_MAP[index_counter] = \\\n",
    "                            {\"include_skill_opt\" : 1 if include_skill_opt else 0, \\\n",
    "                            \"sampling_opt\" : sampling_opt, \\\n",
    "                            \"feature_selection_opt\" : \"none\", \\\n",
    "                            \"algorithm_opt\" : algorithm_opt, \\\n",
    "                            \"random_state_opt\": random_state_opt}\n",
    "                        index_counter += 1\n",
    "                else:\n",
    "                    for feature_selection_opt in FEATURE_SELECTION_OPTIONS:\n",
    "                        for algorithm_opt in MODEL_ALGORITHM_OPTIONS:\n",
    "                            CONFIG_EXPERIMENTS_SCENARIO_MAP[index_counter] = \\\n",
    "                                {\"include_skill_opt\" : 1 if include_skill_opt else 0, \\\n",
    "                                \"sampling_opt\" : sampling_opt, \\\n",
    "                                \"feature_selection_opt\" : feature_selection_opt, \\\n",
    "                                \"algorithm_opt\" : algorithm_opt, \\\n",
    "                                \"random_state_opt\": random_state_opt}\n",
    "                            index_counter += 1\n",
    "\n",
    "def construct_config_experiments_skill_probs_scenario_map():\n",
    "    index_counter = 1\n",
    "    for feature_selection_opt in FEATURE_SELECTION_OPTIONS_FOR_PLAYER_PROBS:\n",
    "        CONFIG_EXPERIMENTS_SKILL_PROBS_SCENARIO_MAP[index_counter] = {\n",
    "            \"random_state_opt\" : \"none\",\n",
    "            \"feature_selection_opt\" : feature_selection_opt\n",
    "        }\n",
    "        index_counter += 1\n",
    "\n",
    "construct_config_experiments_scenario_map()\n",
    "construct_config_experiments_skill_probs_scenario_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS FOR TEST EXPERIMENT RESULT\n",
    "COLUMNS_EVALUATION_METRIC_CLASSIFICATION = [\n",
    "    \"rec_score\",\n",
    "    \"prec_score\",\n",
    "    \"F1_score\",\n",
    "    \"acc_score\",\n",
    "    \"auc_score\",\n",
    "    \"mcc_score\",\n",
    "    \"brier_score\",\n",
    "    \"log_loss_score\",\n",
    "    \"balanced_acc_score\"\n",
    "]\n",
    "COLUMNS_EVALUATION_METRIC_REGRESSION = [\n",
    "    \"mean_squared_error_score\",\n",
    "    \"root_mean_squared_error_score\",\n",
    "    \"auc_score\",\n",
    "    \"brier_score\",\n",
    "    \"log_loss_score\",\n",
    "    \"mean_absolute_error_score\",\n",
    "    \"r_squared_score\",\n",
    "    \"mean_absolute_percentage_error_score\"\n",
    "]\n",
    "COLUMNS_SCENARIO_NAME = [\n",
    "    \"include_skill_opt\",\n",
    "    \"sampling_opt\",\n",
    "    \"feature_selection_opt\",\n",
    "    \"algorithm_opt\",\n",
    "    \"random_state_opt\"\n",
    "]\n",
    "# if (USE_EVALUATION_METRIC_CLASSIFICATION):\n",
    "#     COLUMNS_EXPERIMENT_RESULT = [\"case_number\"] + COLUMNS_SCENARIO_NAME + COLUMNS_EVALUATION_METRIC_CLASSIFICATION\n",
    "# else:\n",
    "#     COLUMNS_EXPERIMENT_RESULT = [\"case_number\"] + COLUMNS_SCENARIO_NAME + COLUMNS_EVALUATION_METRIC_REGRESSION\n",
    "\n",
    "COLUMNS_EXPERIMENT_RESULT = [\"case_number\"] + COLUMNS_SCENARIO_NAME\n",
    "\n",
    "COLUMNS_EXPERIMENT_RESULT_PLAYER_SKILL_PROBS = [\n",
    "    \"case_number\",\n",
    "    \"feature_selection_opt\",\n",
    "    \"random_selection_opt\",\n",
    "    # \"mean_squared_error_score\",\n",
    "    # \"root_mean_squared_error_score\",\n",
    "    # \"mean_absolute_error_score\",\n",
    "    # \"r_squared_score\",\n",
    "    # \"mean_absolute_percentage_error_score\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wyscout = PublicWyscoutLoader(root=\"data/wyscout\")\n",
    "api_opta = OptaLoader(root=\"data/opta\")\n",
    "api_statsbomb = StatsBombLoader(root=\"data/statsbomb\", getter=\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_id : 0   action_name : pass\n",
      "action_id : 1   action_name : cross\n",
      "action_id : 2   action_name : throw_in\n",
      "action_id : 3   action_name : freekick_crossed\n",
      "action_id : 4   action_name : freekick_short\n",
      "action_id : 5   action_name : corner_crossed\n",
      "action_id : 6   action_name : corner_short\n",
      "action_id : 7   action_name : take_on\n",
      "action_id : 8   action_name : foul\n",
      "action_id : 9   action_name : tackle\n",
      "action_id : 10   action_name : interception\n",
      "action_id : 11   action_name : shot\n",
      "action_id : 12   action_name : shot_penalty\n",
      "action_id : 13   action_name : shot_freekick\n",
      "action_id : 14   action_name : keeper_save\n",
      "action_id : 15   action_name : keeper_claim\n",
      "action_id : 16   action_name : keeper_punch\n",
      "action_id : 17   action_name : keeper_pick_up\n",
      "action_id : 18   action_name : clearance\n",
      "action_id : 19   action_name : bad_touch\n",
      "action_id : 20   action_name : non_action\n",
      "action_id : 21   action_name : dribble\n",
      "action_id : 22   action_name : goalkick\n"
     ]
    }
   ],
   "source": [
    "for idx, action_name in enumerate(actiontypes):\n",
    "    print(f'action_id : {idx}   action_name : {action_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bodypart_id : 0   bodypart_name : foot\n",
      "bodypart_id : 1   bodypart_name : head\n",
      "bodypart_id : 2   bodypart_name : other\n",
      "bodypart_id : 3   bodypart_name : head/other\n",
      "bodypart_id : 4   bodypart_name : foot_left\n",
      "bodypart_id : 5   bodypart_name : foot_right\n"
     ]
    }
   ],
   "source": [
    "for idx, bodypart_name in enumerate(bodyparts):\n",
    "    print(f'bodypart_id : {idx}   bodypart_name : {bodypart_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_events_df_to_spadl(events_df, home_team_id, source):\n",
    "    if (source == \"Statsbomb\"):\n",
    "        spadl_events_df = convert_to_actions_statsbomb(events_df, home_team_id)\n",
    "    else:\n",
    "        spadl_events_df = convert_to_actions_wyscout(events_df, home_team_id)\n",
    "    spadl_events_df['time_seconds'] = spadl_events_df['time_seconds'].astype('float64')\n",
    "    spadl_events_df['timestamp'] = pd.to_datetime(spadl_events_df['time_seconds'], unit='s')\n",
    "    return spadl_events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO ADD ADDITIONAL INFO IN RAW SPADL DATAFRAME\n",
    "STANDARD_LENGTH_COURT = 105\n",
    "STANDARD_WIDTH_COURT = 68\n",
    "STANDARD_GOALLINE_WIDTH = 7.32\n",
    "STANDARD_LENGTH_COURT_STATSBOMB = 120\n",
    "STANDARD_WIDTH_COURT_STATSBOMB = 80\n",
    "\n",
    "# Helper Functions\n",
    "def calculate_distance_pass(coordinate_x, coordinate_y, end_x, end_y):\n",
    "    distance_passing = math.sqrt((abs(end_x - coordinate_x)) ** 2 + (abs(end_y - coordinate_y)) ** 2)\n",
    "    return distance_passing\n",
    "\n",
    "def calculate_distance_pass_apply_df(row):\n",
    "    return calculate_distance_pass(row['start_x'], row['start_y'], row['end_x'], row['end_y'])\n",
    "\n",
    "def filter_out_is_home_team_apply_df(row, home_team_id):\n",
    "    return 1 if row['team_id'] == home_team_id else 0\n",
    "\n",
    "def calculate_nearest_distance_from_sideline(coordinate_x, coordinate_y):\n",
    "    distance_to_left = coordinate_x\n",
    "    distance_to_bottom = coordinate_y\n",
    "    distance_to_top = STANDARD_WIDTH_COURT - coordinate_y\n",
    "    distance_to_right = STANDARD_LENGTH_COURT - coordinate_x\n",
    "    return min(distance_to_top, distance_to_bottom, distance_to_left, distance_to_right)\n",
    "\n",
    "def calculate_nearest_distance_from_sideline_apply_df(row):\n",
    "    return calculate_nearest_distance_from_sideline(row['start_x'], row['start_y'])\n",
    "\n",
    "def calculate_nearest_receiver_distance_from_sideline_apply_df(row):\n",
    "    return calculate_nearest_distance_from_sideline(row['end_x'], row['end_y'])\n",
    "\n",
    "def calculate_distance_with_opposing_goal(coordinate_x, coordinate_y, is_home_team):\n",
    "    distance_vertical = abs((STANDARD_WIDTH_COURT / 2) - coordinate_y)\n",
    "    if (is_home_team):\n",
    "        distance_horizontal = STANDARD_LENGTH_COURT - coordinate_x\n",
    "    else:\n",
    "        distance_horizontal = coordinate_x\n",
    "    return math.sqrt(distance_vertical ** 2 + distance_horizontal ** 2)\n",
    "\n",
    "def calculate_distance_with_opposing_goal_apply_df(row, home_team_id):\n",
    "    return calculate_distance_with_opposing_goal(row['start_x'], row['start_y'], (row['team_id'] == home_team_id))\n",
    "\n",
    "def calculate_distance_receiver_with_opposing_goal_apply_df(row, home_team_id):\n",
    "    return calculate_distance_with_opposing_goal(row['end_x'], row['end_y'], (row['team_id'] == home_team_id))\n",
    "\n",
    "def calculate_distance_between_two_coordinates(x1, y1, x2, y2):\n",
    "    return math.sqrt(abs(x2-x1) ** 2 + abs(y2-y1) ** 2)\n",
    "\n",
    "def calculate_angle_pass(coordinate_x, coordinate_y, end_x, end_y, is_home_team):\n",
    "    if (is_home_team):\n",
    "        coordinate_x_goal = STANDARD_LENGTH_COURT\n",
    "    else:\n",
    "        coordinate_x_goal = 0\n",
    "    coordinate_y_goal = STANDARD_WIDTH_COURT / 2\n",
    "\n",
    "    distance_passer_to_goal = calculate_distance_between_two_coordinates(coordinate_x_goal, coordinate_y_goal, coordinate_x, coordinate_y)\n",
    "    distance_receiver_to_goal = calculate_distance_between_two_coordinates(coordinate_x_goal, coordinate_y_goal, end_x, end_y)\n",
    "    distance_passer_to_receiver = calculate_distance_between_two_coordinates(coordinate_x, coordinate_y, end_x, end_y)\n",
    "\n",
    "    if (coordinate_x == end_x) and (coordinate_y == end_y):\n",
    "        return 0\n",
    "    else:\n",
    "        cosine_value = (distance_passer_to_goal ** 2 + distance_passer_to_receiver ** 2 - distance_receiver_to_goal ** 2) / (2 * distance_passer_to_goal * distance_passer_to_receiver)\n",
    "        if (cosine_value > 1):\n",
    "            cosine_value = 1\n",
    "        elif (cosine_value < -1):\n",
    "            cosine_value = -1\n",
    "        return math.degrees(math.acos(cosine_value))\n",
    "\n",
    "def calculate_angle_pass_apply_df(row, home_team_id):\n",
    "    return calculate_angle_pass(row['start_x'], row['start_y'], row['end_x'], row['end_y'], (row['team_id'] == home_team_id))\n",
    "\n",
    "# Helper functions specific to statsbomb opponent data\n",
    "def filter_out_non_opponent_coordinate_freeze_frame(freeze_frame_360_list):\n",
    "    if (freeze_frame_360_list == None or not isinstance(freeze_frame_360_list, list)):\n",
    "        return []\n",
    "    return [x for x in freeze_frame_360_list if x['teammate'] == False and x['actor'] == False]\n",
    "\n",
    "def convert_statsbomb_coordinate_to_spadl_coordinate(coordinate_x, coordinate_y):\n",
    "    converted_coordinate_x = (STANDARD_LENGTH_COURT / STANDARD_LENGTH_COURT_STATSBOMB) * coordinate_x\n",
    "    converted_coordinate_y = (STANDARD_WIDTH_COURT / STANDARD_WIDTH_COURT_STATSBOMB) * (STANDARD_WIDTH_COURT_STATSBOMB - coordinate_y)\n",
    "    return (converted_coordinate_x, converted_coordinate_y)\n",
    "\n",
    "def calculate_distance_opponent_apply_df(row):\n",
    "    freeze_frame_360_opponents = filter_out_non_opponent_coordinate_freeze_frame(row['freeze_frame_360'])\n",
    "    list_distance_opponent = []\n",
    "    for object_loc in freeze_frame_360_opponents:\n",
    "        opponent_x, opponent_y = convert_statsbomb_coordinate_to_spadl_coordinate(object_loc['location'][0], object_loc['location'][1])\n",
    "        distance_opponent = calculate_distance_between_two_coordinates(row['start_x'], row['start_y'], opponent_x, opponent_y)\n",
    "        list_distance_opponent.append(distance_opponent)\n",
    "    return min(list_distance_opponent) if len(list_distance_opponent) > 0 else 0\n",
    "\n",
    "def calculate_distance_receiver_opponent_apply_df(row):\n",
    "    freeze_frame_360_opponents = filter_out_non_opponent_coordinate_freeze_frame(row['freeze_frame_360'])\n",
    "    list_distance_opponent = []\n",
    "    for object_loc in freeze_frame_360_opponents:\n",
    "        opponent_x, opponent_y = convert_statsbomb_coordinate_to_spadl_coordinate(object_loc['location'][0], object_loc['location'][1])\n",
    "        distance_opponent = calculate_distance_between_two_coordinates(row['end_x'], row['end_y'], opponent_x, opponent_y)\n",
    "        list_distance_opponent.append(distance_opponent)\n",
    "    return min(list_distance_opponent) if len(list_distance_opponent) > 0 else 0\n",
    "\n",
    "def calculate_num_opponent_closer_goal(start_x, start_y, freeze_frame_360, is_home_team):\n",
    "    freeze_frame_360_opponents = filter_out_non_opponent_coordinate_freeze_frame(freeze_frame_360)\n",
    "    if (is_home_team):\n",
    "        coordinate_x_goal = STANDARD_LENGTH_COURT\n",
    "    else:\n",
    "        coordinate_x_goal = 0\n",
    "    coordinate_y_goal = STANDARD_WIDTH_COURT / 2\n",
    "\n",
    "    num_opponent_closer_to_goal = 0\n",
    "    for object_loc in freeze_frame_360_opponents:\n",
    "        opponent_x, opponent_y = convert_statsbomb_coordinate_to_spadl_coordinate(object_loc['location'][0], object_loc['location'][1])\n",
    "        distance_passer_to_goal = calculate_distance_between_two_coordinates(start_x, start_y, coordinate_x_goal, coordinate_y_goal)\n",
    "        distance_opponent_to_goal = calculate_distance_between_two_coordinates(opponent_x, opponent_y, coordinate_x_goal, coordinate_y_goal)\n",
    "        if (distance_opponent_to_goal < distance_passer_to_goal):\n",
    "            num_opponent_closer_to_goal += 1\n",
    "    return num_opponent_closer_to_goal\n",
    "\n",
    "def calculate_num_opponent_closer_goal_apply_df(row, home_team_id):\n",
    "    return calculate_num_opponent_closer_goal(row['start_x'], row['start_y'], row['freeze_frame_360'], (row['team_id'] == home_team_id))\n",
    "\n",
    "def calculate_num_opponent_closer_goal_receiver_apply_df(row, home_team_id):\n",
    "    return calculate_num_opponent_closer_goal(row['end_x'], row['end_y'], row['freeze_frame_360'], (row['team_id'] == home_team_id))\n",
    "\n",
    "def calculate_num_opponent_in_path(start_x, start_y, freeze_frame_360):\n",
    "    path_distance = 10\n",
    "    freeze_frame_360_opponents = filter_out_non_opponent_coordinate_freeze_frame(freeze_frame_360)\n",
    "    num_opponent_in_path = 0\n",
    "    for object_loc in freeze_frame_360_opponents:\n",
    "        opponent_x, opponent_y = convert_statsbomb_coordinate_to_spadl_coordinate(object_loc['location'][0], object_loc['location'][1])\n",
    "        distance_with_opponent = calculate_distance_between_two_coordinates(start_x, start_y, opponent_x, opponent_y)\n",
    "        if (distance_with_opponent <= path_distance):\n",
    "            num_opponent_in_path += 1\n",
    "    return num_opponent_in_path\n",
    "\n",
    "def calculate_num_opponent_in_path_apply_df(row):\n",
    "    return calculate_num_opponent_in_path(row['start_x'], row['start_y'], row['freeze_frame_360'])\n",
    "\n",
    "def calculate_num_opponent_in_path_receiver_apply_df(row):\n",
    "    return calculate_num_opponent_in_path(row['end_x'], row['end_y'], row['freeze_frame_360'])\n",
    "\n",
    "def calculate_num_opponent_based_on_angle_path_per_side(row, lower_limit_deg, upper_limit_deg, before_midpoint, opponent_x, opponent_y, is_actor_side):\n",
    "    radius_path_length = calculate_distance_between_two_coordinates(row['start_x'], row['start_y'], row['end_x'], row['end_y'])\n",
    "    if (is_actor_side):\n",
    "        distance_with_opponent = calculate_distance_between_two_coordinates(row['start_x'], row['start_y'], opponent_x, opponent_y)\n",
    "        distance_opponent_with_target = calculate_distance_between_two_coordinates(row['end_x'], row['end_y'], opponent_x, opponent_y)\n",
    "    else:\n",
    "        distance_with_opponent = calculate_distance_between_two_coordinates(row['end_x'], row['end_y'], opponent_x, opponent_y)\n",
    "        distance_opponent_with_target = calculate_distance_between_two_coordinates(row['start_x'], row['start_y'], opponent_x, opponent_y)\n",
    "    \n",
    "    if (distance_opponent_with_target == 0) or (radius_path_length == 0):\n",
    "        angle_opponent_with_path = 0\n",
    "    else:\n",
    "        cosine_value = (distance_with_opponent ** 2 + radius_path_length ** 2 - distance_opponent_with_target ** 2) / (2 * distance_with_opponent * radius_path_length)\n",
    "        if (cosine_value > 1):\n",
    "            cosine_value = 1\n",
    "        elif (cosine_value < -1):\n",
    "            cosine_value = -1\n",
    "        angle_opponent_with_path = math.degrees(math.acos(cosine_value))\n",
    "\n",
    "    num_opponent_in_this_angle = 0\n",
    "    if (distance_with_opponent <= radius_path_length):\n",
    "        if (before_midpoint and (distance_with_opponent <= (radius_path_length / 2))) or (not before_midpoint and (distance_with_opponent > (radius_path_length / 2))):\n",
    "            if (angle_opponent_with_path == 0) and (upper_limit_deg == 45):\n",
    "                num_opponent_in_this_angle += 1\n",
    "            elif (angle_opponent_with_path > lower_limit_deg) and (angle_opponent_with_path <= upper_limit_deg):\n",
    "                num_opponent_in_this_angle += 1\n",
    "    return num_opponent_in_this_angle\n",
    "\n",
    "def calculate_num_opponent_based_on_angle_path_apply_df(row, lower_limit_deg, upper_limit_deg, before_midpoint, is_actor_side):\n",
    "    freeze_frame_360_opponents = filter_out_non_opponent_coordinate_freeze_frame(row['freeze_frame_360'])\n",
    "    num_opponent_in_this_angle = 0\n",
    "    for object_loc in freeze_frame_360_opponents:\n",
    "        opponent_x, opponent_y = convert_statsbomb_coordinate_to_spadl_coordinate(object_loc['location'][0], object_loc['location'][1])\n",
    "        num_opponent_in_this_angle += calculate_num_opponent_based_on_angle_path_per_side(row, lower_limit_deg, upper_limit_deg, before_midpoint, opponent_x, opponent_y, is_actor_side)\n",
    "    return num_opponent_in_this_angle\n",
    "\n",
    "# Convert horizontal start coordinate value (start_x) for away team\n",
    "def convert_horizontal_start_coordinate_away_team(row, home_team_id):\n",
    "    return row['start_x'] if row['team_id'] == home_team_id else (STANDARD_LENGTH_COURT - row['start_x'])\n",
    "\n",
    "# Convert vertical start coordinate value (end_y) for away team\n",
    "def convert_vertical_start_coordinate_away_team(row, home_team_id):\n",
    "    return row['start_y'] if row['team_id'] == home_team_id else (STANDARD_WIDTH_COURT - row['start_y'])\n",
    "\n",
    "# Convert horizontal end coordinate value (end_x) for away team\n",
    "def convert_horizontal_end_coordinate_away_team(row, home_team_id):\n",
    "    return row['end_x'] if row['team_id'] == home_team_id else (STANDARD_LENGTH_COURT - row['end_x'])\n",
    "\n",
    "# Convert vertical start coordinate value (end_y) for away team\n",
    "def convert_vertical_end_coordinate_away_team(row, home_team_id):\n",
    "    return row['end_y'] if row['team_id'] == home_team_id else (STANDARD_WIDTH_COURT - row['end_y'])\n",
    "\n",
    "# Add distance passing column\n",
    "def add_distance_pass_to_spadl_df(spadl_df):\n",
    "    spadl_df['distance_pass'] = spadl_df.apply(calculate_distance_pass_apply_df, axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Add is_home_team column (boolean 0/1)\n",
    "def add_is_home_team_column_to_spadl_df(spadl_df, home_team_id):\n",
    "    spadl_df['is_home_team'] = spadl_df.apply(lambda x : filter_out_is_home_team_apply_df(x, home_team_id), axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Feature 1 : distance nearest sideline\n",
    "def add_distance_sideline_column_to_spadl_df(spadl_df):\n",
    "    spadl_df['distance_sideline'] = spadl_df.apply(calculate_nearest_distance_from_sideline_apply_df, axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Feature 2 : distance goal\n",
    "def add_distance_goal_column_to_spadl_df(spadl_df, home_team_id):\n",
    "    spadl_df['distance_goal'] = spadl_df.apply(lambda x : calculate_distance_with_opposing_goal_apply_df(x, home_team_id), axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Feature 3 : distance receiver nearest sideline \n",
    "def add_distance_receiver_sideline_column_to_spadl_df(spadl_df):\n",
    "    spadl_df['distance_receiver_sideline'] = spadl_df.apply(calculate_nearest_receiver_distance_from_sideline_apply_df, axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Feature 4 : distance receiver goal\n",
    "def add_distance_receiver_goal_column_to_spadl_df(spadl_df, home_team_id):\n",
    "    spadl_df['distance_receiver_goal'] = spadl_df.apply(lambda x : calculate_distance_receiver_with_opposing_goal_apply_df(x, home_team_id), axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Feature 5 : angle\n",
    "def add_angle_pass_column_to_spadl_df(spadl_df, home_team_id):\n",
    "    spadl_df['angle_pass'] = spadl_df.apply(lambda x : calculate_angle_pass_apply_df(x, home_team_id), axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Feature 6 : reverse coordinate (start_x, start_y) and (end_x, end_y) for away team\n",
    "def convert_start_and_end_coordinates_in_spadl_df(spadl_df, home_team_id):\n",
    "    spadl_df['start_x'] = spadl_df.apply(lambda x : convert_horizontal_start_coordinate_away_team(x, home_team_id), axis=1)\n",
    "    spadl_df['start_y'] = spadl_df.apply(lambda x : convert_vertical_start_coordinate_away_team(x, home_team_id), axis=1)\n",
    "    spadl_df['end_x'] = spadl_df.apply(lambda x : convert_horizontal_end_coordinate_away_team(x, home_team_id), axis=1)\n",
    "    spadl_df['end_y'] = spadl_df.apply(lambda x : convert_vertical_end_coordinate_away_team(x, home_team_id), axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Opponent Feature 1 : distance opponent\n",
    "def add_distance_opponent_column_to_spadl_df(spadl_df):\n",
    "    spadl_df['distance_opponent'] = spadl_df.apply(calculate_distance_opponent_apply_df, axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Opponent Feature 2 : opponents closer to goal\n",
    "def add_num_opponent_closer_goal_column_to_spadl_df(spadl_df, home_team_id):\n",
    "    spadl_df['num_opponent_closer_goal'] = spadl_df.apply(lambda x : calculate_num_opponent_closer_goal_apply_df(x, home_team_id), axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Opponent Feature 3 : distance receiver opponent\n",
    "def add_distance_receiver_opponent_column_to_spadl_df(spadl_df):\n",
    "    spadl_df['distance_receiver_opponent'] = spadl_df.apply(calculate_distance_receiver_opponent_apply_df, axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Opponent Feature 4 : opponents closer to goal receiver\n",
    "def add_num_opponent_closer_goal_receiver_column_to_spadl_df(spadl_df, home_team_id):\n",
    "    spadl_df['num_opponent_closer_goal_receiver'] = spadl_df.apply(lambda x : calculate_num_opponent_closer_goal_receiver_apply_df(x, home_team_id), axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Opponent Feature 5 : opponents in path\n",
    "def add_num_opponent_in_path_column_to_spadl_df(spadl_df):\n",
    "    spadl_df['num_opponent_in_path'] = spadl_df.apply(calculate_num_opponent_in_path_apply_df, axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Opponent Feature 6 : opponents in path receiver\n",
    "def add_num_opponent_in_path_receiver_column_to_spadl_df(spadl_df):\n",
    "    spadl_df['num_opponent_in_path_receiver'] = spadl_df.apply(calculate_num_opponent_in_path_receiver_apply_df, axis=1)\n",
    "    return spadl_df\n",
    "\n",
    "# Opponent Feature New 1 : add proposed features detect opponent\n",
    "def add_num_opponent_based_on_angle_path_to_spadl_df(spadl_df):\n",
    "    # Actor Side\n",
    "    spadl_df['num_opponent_0_and_45_before_midpoint_actor'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 0, 45, True, True), axis=1)\n",
    "    spadl_df['num_opponent_0_and_45_after_midpoint_actor'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 0, 45, False, True), axis=1)\n",
    "    spadl_df['num_opponent_45_and_90_before_midpoint_actor'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 45, 90, True, True), axis=1)\n",
    "    spadl_df['num_opponent_45_and_90_after_midpoint_actor'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 45, 90, False, True), axis=1)\n",
    "    spadl_df['num_opponent_90_and_135_before_midpoint_actor'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 90, 135, True, True), axis=1)\n",
    "    spadl_df['num_opponent_90_and_135_after_midpoint_actor'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 90, 135, False, True), axis=1)\n",
    "    spadl_df['num_opponent_135_and_180_before_midpoint_actor'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 135, 180, True, True), axis=1)\n",
    "    spadl_df['num_opponent_135_and_180_after_midpoint_actor'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 135, 180, False, True), axis=1)\n",
    "    # Receiver Side\n",
    "    spadl_df['num_opponent_0_and_45_before_midpoint_receiver'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 0, 45, True, False), axis=1)\n",
    "    spadl_df['num_opponent_0_and_45_after_midpoint_receiver'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 0, 45, False, False), axis=1)\n",
    "    spadl_df['num_opponent_45_and_90_before_midpoint_receiver'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 45, 90, True, False), axis=1)\n",
    "    spadl_df['num_opponent_45_and_90_after_midpoint_receiver'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 45, 90, False, False), axis=1)\n",
    "    spadl_df['num_opponent_90_and_135_before_midpoint_receiver'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 90, 135, True, False), axis=1)\n",
    "    spadl_df['num_opponent_90_and_135_after_midpoint_receiver'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 90, 135, False, False), axis=1)\n",
    "    spadl_df['num_opponent_135_and_180_before_midpoint_receiver'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 135, 180, True, False), axis=1)\n",
    "    spadl_df['num_opponent_135_and_180_after_midpoint_receiver'] = spadl_df.apply(lambda x : calculate_num_opponent_based_on_angle_path_apply_df(x, 135, 180, False, False), axis=1)\n",
    "    \n",
    "    return spadl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all dataset action specific type, export them to csv files\n",
    "# Pass (action_id = 0), Cross (action_id = 1)\n",
    "PASS_ACTION_ID = [0,1] \n",
    "\n",
    "def collect_raw_pass_spadl_df(source=\"Wyscout\", period=1):\n",
    "    if source == \"Statsbomb\":\n",
    "        api = api_statsbomb\n",
    "    else:\n",
    "        api = api_wyscout\n",
    "    list_competitions_ids = []\n",
    "    list_game_ids = []\n",
    "\n",
    "    competitions_df = api.competitions()\n",
    "    for _, row in competitions_df.iterrows():\n",
    "        if source == \"Statsbomb\":\n",
    "            if row['competition_gender'] == 'male':\n",
    "                list_competitions_ids.append((row['competition_id'], row['season_id']))\n",
    "        else:\n",
    "            list_competitions_ids.append((row['competition_id'], row['season_id']))\n",
    "        \n",
    "    for competition_id, season_id in list_competitions_ids:\n",
    "        games_df = api.games(competition_id, season_id)\n",
    "        for _, row in games_df.iterrows():\n",
    "            list_game_ids.append((row['game_id'], row['home_team_id'], row['away_team_id']))\n",
    "            \n",
    "    for game_id, home_team_id, away_team_id in list_game_ids:\n",
    "        try:\n",
    "            if (source == \"Statsbomb\"):\n",
    "                this_game_events_df = api.events(game_id, load_360=True)\n",
    "            else:\n",
    "                this_game_events_df = api.events(game_id)\n",
    "            this_game_events_spadl_df = convert_events_df_to_spadl(this_game_events_df, home_team_id, source)\n",
    "            \n",
    "            # Add column 360 data into events spadl data (Statsbomb)\n",
    "            if (source == \"Statsbomb\"):\n",
    "                this_game_events_spadl_df = pd.merge(this_game_events_spadl_df, this_game_events_df[[\"event_id\", \"visible_area_360\", \"freeze_frame_360\"]], how=\"inner\", left_on=\"original_event_id\", right_on=\"event_id\")\n",
    "                this_game_events_spadl_df.dropna(subset=[\"freeze_frame_360\"])\n",
    "\n",
    "            # Filter action id with type pass only, pick only data from first period\n",
    "            this_game_events_spadl_df = this_game_events_spadl_df[this_game_events_spadl_df['type_id'].isin(PASS_ACTION_ID)]\n",
    "            # if (period != None):\n",
    "            #     this_game_events_spadl_df = this_game_events_spadl_df[this_game_events_spadl_df['period_id'] == period]\n",
    "            # else:\n",
    "            #     this_game_events_spadl_df = this_game_events_spadl_df[this_game_events_spadl_df['period_id'] == 1]\n",
    "            \n",
    "            # Add additional computed column to support xpass model                \n",
    "            this_game_events_spadl_df = add_is_home_team_column_to_spadl_df(this_game_events_spadl_df, home_team_id)\n",
    "            this_game_events_spadl_df = add_distance_pass_to_spadl_df(this_game_events_spadl_df)\n",
    "            this_game_events_spadl_df = add_distance_sideline_column_to_spadl_df(this_game_events_spadl_df)\n",
    "            this_game_events_spadl_df = add_distance_goal_column_to_spadl_df(this_game_events_spadl_df, home_team_id)\n",
    "            this_game_events_spadl_df = add_distance_receiver_sideline_column_to_spadl_df(this_game_events_spadl_df)\n",
    "            this_game_events_spadl_df = add_distance_receiver_goal_column_to_spadl_df(this_game_events_spadl_df, home_team_id)\n",
    "            this_game_events_spadl_df = add_angle_pass_column_to_spadl_df(this_game_events_spadl_df, home_team_id)\n",
    "            if (source == \"Statsbomb\"):\n",
    "                this_game_events_spadl_df = add_distance_opponent_column_to_spadl_df(this_game_events_spadl_df)\n",
    "                this_game_events_spadl_df = add_num_opponent_closer_goal_column_to_spadl_df(this_game_events_spadl_df, home_team_id)\n",
    "                this_game_events_spadl_df = add_distance_receiver_opponent_column_to_spadl_df(this_game_events_spadl_df)\n",
    "                this_game_events_spadl_df = add_num_opponent_closer_goal_receiver_column_to_spadl_df(this_game_events_spadl_df, home_team_id)\n",
    "                this_game_events_spadl_df = add_num_opponent_in_path_column_to_spadl_df(this_game_events_spadl_df)\n",
    "                this_game_events_spadl_df = add_num_opponent_in_path_receiver_column_to_spadl_df(this_game_events_spadl_df)\n",
    "                this_game_events_spadl_df = add_num_opponent_based_on_angle_path_to_spadl_df(this_game_events_spadl_df)\n",
    "            \n",
    "            # (Should be done in last step!) \n",
    "            # Convert coordinate (start_x, start_y) and (end_x, end_y) for away team\n",
    "            this_game_events_spadl_df = convert_start_and_end_coordinates_in_spadl_df(this_game_events_spadl_df, home_team_id)\n",
    "\n",
    "            # Export to external csv iteratively\n",
    "            this_game_events_spadl_df.to_csv(f'data/training_data_xpass/{game_id}_{home_team_id}_{away_team_id}_xpass_data.csv') \n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print(f'File 360 data not found {game_id}-{home_team_id}-{away_team_id}')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DRIVER (comment it if csv files already loaded)\n",
    "# collect_raw_pass_spadl_df(source=\"Statsbomb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv datas already retrieved then concat them into one big dataframe\n",
    "import os\n",
    "\n",
    "DIRECTORY_XPASS_CSV_DATAS = \"data/training_data_xpass\"\n",
    "\n",
    "def load_and_concat_xpass_df_from_csv():\n",
    "    list_pass_event_df = []\n",
    "    for filename in os.listdir(DIRECTORY_XPASS_CSV_DATAS):\n",
    "        f = os.path.join(DIRECTORY_XPASS_CSV_DATAS, filename)\n",
    "        if os.path.isfile(f):\n",
    "            pass_event_df = pd.read_csv(f)\n",
    "            list_pass_event_df.append(pass_event_df)\n",
    "    return pd.concat(list_pass_event_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>game_id</th>\n",
       "      <th>original_event_id</th>\n",
       "      <th>period_id</th>\n",
       "      <th>time_seconds</th>\n",
       "      <th>team_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>start_x</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>...</th>\n",
       "      <th>num_opponent_135_and_180_before_midpoint_actor</th>\n",
       "      <th>num_opponent_135_and_180_after_midpoint_actor</th>\n",
       "      <th>num_opponent_0_and_45_before_midpoint_receiver</th>\n",
       "      <th>num_opponent_0_and_45_after_midpoint_receiver</th>\n",
       "      <th>num_opponent_45_and_90_before_midpoint_receiver</th>\n",
       "      <th>num_opponent_45_and_90_after_midpoint_receiver</th>\n",
       "      <th>num_opponent_90_and_135_before_midpoint_receiver</th>\n",
       "      <th>num_opponent_90_and_135_after_midpoint_receiver</th>\n",
       "      <th>num_opponent_135_and_180_before_midpoint_receiver</th>\n",
       "      <th>num_opponent_135_and_180_after_midpoint_receiver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3788741</td>\n",
       "      <td>5c888f58-fe77-459b-ab3b-a2fa5fb8ab16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909</td>\n",
       "      <td>11086.0</td>\n",
       "      <td>52.058824</td>\n",
       "      <td>34.430380</td>\n",
       "      <td>27.794118</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3788741</td>\n",
       "      <td>84b9b798-0fbe-45bc-a4bf-3621959f29ce</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>909</td>\n",
       "      <td>8963.0</td>\n",
       "      <td>31.058824</td>\n",
       "      <td>42.693671</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>3788741</td>\n",
       "      <td>bfcfd5ad-1dda-44c9-9f3d-9b33b59983a6</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>914</td>\n",
       "      <td>6954.0</td>\n",
       "      <td>2.029412</td>\n",
       "      <td>57.929114</td>\n",
       "      <td>6.088235</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>3788741</td>\n",
       "      <td>14604dfa-65b1-40c0-a11e-7c6b037806c0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>914</td>\n",
       "      <td>7036.0</td>\n",
       "      <td>7.147059</td>\n",
       "      <td>35.377215</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>3788741</td>\n",
       "      <td>2b3361c2-de34-4eea-bcd8-1815de59a72d</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>914</td>\n",
       "      <td>7173.0</td>\n",
       "      <td>24.529412</td>\n",
       "      <td>25.908861</td>\n",
       "      <td>27.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  game_id                     original_event_id  period_id  \\\n",
       "0           0  3788741  5c888f58-fe77-459b-ab3b-a2fa5fb8ab16          1   \n",
       "1           2  3788741  84b9b798-0fbe-45bc-a4bf-3621959f29ce          1   \n",
       "2           7  3788741  bfcfd5ad-1dda-44c9-9f3d-9b33b59983a6          1   \n",
       "3           9  3788741  14604dfa-65b1-40c0-a11e-7c6b037806c0          1   \n",
       "4          11  3788741  2b3361c2-de34-4eea-bcd8-1815de59a72d          1   \n",
       "\n",
       "   time_seconds  team_id  player_id    start_x    start_y      end_x  ...  \\\n",
       "0           0.0      909    11086.0  52.058824  34.430380  27.794118  ...   \n",
       "1           4.0      909     8963.0  31.058824  42.693671  61.500000  ...   \n",
       "2          16.0      914     6954.0   2.029412  57.929114   6.088235  ...   \n",
       "3          20.0      914     7036.0   7.147059  35.377215  16.500000  ...   \n",
       "4          24.0      914     7173.0  24.529412  25.908861  27.176471  ...   \n",
       "\n",
       "   num_opponent_135_and_180_before_midpoint_actor  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "\n",
       "   num_opponent_135_and_180_after_midpoint_actor  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   num_opponent_0_and_45_before_midpoint_receiver  \\\n",
       "0                                               1   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "\n",
       "   num_opponent_0_and_45_after_midpoint_receiver  \\\n",
       "0                                              4   \n",
       "1                                              7   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   num_opponent_45_and_90_before_midpoint_receiver  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "  num_opponent_45_and_90_after_midpoint_receiver  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "  num_opponent_90_and_135_before_midpoint_receiver  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "  num_opponent_90_and_135_after_midpoint_receiver  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "\n",
       "  num_opponent_135_and_180_before_midpoint_receiver  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "\n",
       "   num_opponent_135_and_180_after_midpoint_receiver  \n",
       "0                                                 0  \n",
       "1                                                 0  \n",
       "2                                                 0  \n",
       "3                                                 0  \n",
       "4                                                 0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JOIN ALREADY CONSTRUCTED PLAYER SKILLS DATASET WITH ORIGIN EVENT DATASET WYSCOUT\n",
    "DIRECTORY_FINAL_PLAYERS_CSV_DATAS = \"data/players_skill_dataset/final_players_skill_dataset.csv\"\n",
    "\n",
    "player_skills_dataset = pd.read_csv(DIRECTORY_FINAL_PLAYERS_CSV_DATAS)\n",
    "big_dataframe_xpass_model = load_and_concat_xpass_df_from_csv()\n",
    "# big_dataframe_xpass_model = big_dataframe_xpass_model.merge(player_skills_dataset, how='inner',on='player_id')\n",
    "big_dataframe_xpass_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_event_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>result_id</th>\n",
       "      <th>distance_pass</th>\n",
       "      <th>distance_opponent</th>\n",
       "      <th>distance_receiver_opponent</th>\n",
       "      <th>num_opponent_in_path</th>\n",
       "      <th>num_opponent_in_path_receiver</th>\n",
       "      <th>num_opponent_0_and_45_before_midpoint_actor</th>\n",
       "      <th>num_opponent_0_and_45_after_midpoint_actor</th>\n",
       "      <th>num_opponent_0_and_45_before_midpoint_receiver</th>\n",
       "      <th>num_opponent_0_and_45_after_midpoint_receiver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5c888f58-fe77-459b-ab3b-a2fa5fb8ab16</td>\n",
       "      <td>11086.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.109679</td>\n",
       "      <td>7.441703</td>\n",
       "      <td>10.901622</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84b9b798-0fbe-45bc-a4bf-3621959f29ce</td>\n",
       "      <td>8963.0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.535774</td>\n",
       "      <td>5.353386</td>\n",
       "      <td>25.648747</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bfcfd5ad-1dda-44c9-9f3d-9b33b59983a6</td>\n",
       "      <td>6954.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.631042</td>\n",
       "      <td>80.993213</td>\n",
       "      <td>70.193896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14604dfa-65b1-40c0-a11e-7c6b037806c0</td>\n",
       "      <td>7036.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.144586</td>\n",
       "      <td>60.844747</td>\n",
       "      <td>49.702524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2b3361c2-de34-4eea-bcd8-1815de59a72d</td>\n",
       "      <td>7173.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.048710</td>\n",
       "      <td>35.439819</td>\n",
       "      <td>29.704443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      original_event_id  player_id  result_id  distance_pass  \\\n",
       "0  5c888f58-fe77-459b-ab3b-a2fa5fb8ab16    11086.0          1      26.109679   \n",
       "1  84b9b798-0fbe-45bc-a4bf-3621959f29ce     8963.0          1      49.535774   \n",
       "2  bfcfd5ad-1dda-44c9-9f3d-9b33b59983a6     6954.0          1      20.631042   \n",
       "3  14604dfa-65b1-40c0-a11e-7c6b037806c0     7036.0          1      12.144586   \n",
       "4  2b3361c2-de34-4eea-bcd8-1815de59a72d     7173.0          1      23.048710   \n",
       "\n",
       "   distance_opponent  distance_receiver_opponent  num_opponent_in_path  \\\n",
       "0           7.441703                   10.901622                     4   \n",
       "1           5.353386                   25.648747                     1   \n",
       "2          80.993213                   70.193896                     0   \n",
       "3          60.844747                   49.702524                     0   \n",
       "4          35.439819                   29.704443                     0   \n",
       "\n",
       "   num_opponent_in_path_receiver  num_opponent_0_and_45_before_midpoint_actor  \\\n",
       "0                              0                                            2   \n",
       "1                              0                                            4   \n",
       "2                              0                                            0   \n",
       "3                              0                                            0   \n",
       "4                              0                                            0   \n",
       "\n",
       "   num_opponent_0_and_45_after_midpoint_actor  \\\n",
       "0                                           2   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   num_opponent_0_and_45_before_midpoint_receiver  \\\n",
       "0                                               1   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "\n",
       "   num_opponent_0_and_45_after_midpoint_receiver  \n",
       "0                                              4  \n",
       "1                                              7  \n",
       "2                                              0  \n",
       "3                                              0  \n",
       "4                                              0  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT ONLY FEATURED COLUMN FROM BIG DATASETS\n",
    "# features_column_included = [\"start_x\", \"start_y\", \"end_x\", \"end_y\", \"player_id\", \"original_event_id\", \"distance_pass\", \"distance_sideline\", \n",
    "#                             \"distance_goal\", \"distance_receiver_sideline\", \"distance_receiver_goal\", \"angle_pass\", \n",
    "#                             \"distance_opponent\", \"num_opponent_closer_goal\", \"distance_receiver_opponent\", \"num_opponent_closer_goal_receiver\", \n",
    "#                             \"num_opponent_in_path\", \"num_opponent_in_path_receiver\", \"result_id\"]\n",
    "features_column_included = [\"player_id\", \"original_event_id\", \"distance_pass\", \n",
    "                            \"result_id\", \"num_opponent_in_path\", \"num_opponent_in_path_receiver\", \n",
    "                            \"distance_opponent\", \"distance_receiver_opponent\",\n",
    "                            \"num_opponent_0_and_45_before_midpoint_actor\",\n",
    "                            \"num_opponent_0_and_45_after_midpoint_actor\",\n",
    "                            \"num_opponent_0_and_45_before_midpoint_receiver\",\n",
    "                            \"num_opponent_0_and_45_after_midpoint_receiver\"]\n",
    "player_skills_column_included = [\"acceleration\", \"aggression\", \"agility\", \"balance\", \"ball_control\",\n",
    "                                 \"composure\", \"crossing\", \"curve\", \"dribbling\", \"finishing\",\n",
    "                                 \"freekick_accuracy\", \"heading_accuracy\", \"interceptions\", \"jumping\", \"long_passing\",\n",
    "                                 \"long_shots\", \"marking\", \"penalties\", \"positioning\", \"reactions\",\n",
    "                                 \"shot_power\", \"sliding_tackle\", \"sprint_speed\", \"stamina\", \"short_passing\",\n",
    "                                 \"standing_tackle\", \"strength\", \"vision\", \"volleys\"]\n",
    "player_attribute_column_included = [\"height_cm\", \"weight_kgs\", \"age\"]\n",
    "\n",
    "big_dataframe_xpass_model = big_dataframe_xpass_model[[c for c in big_dataframe_xpass_model.columns if c in (features_column_included + player_skills_column_included + player_attribute_column_included)]]\n",
    "big_dataframe_xpass_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>statistic_success_action_probs</th>\n",
       "      <th>statistic_success_action_among_players</th>\n",
       "      <th>statistic_success_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>ZoltÃ¡n Stieber</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.064937e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Ari Freyr SkÃºlason</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.072728e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Benjaloud Youssouf</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>4.137665e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Rui Pedro da Rocha Fonte</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.225975e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>Jean-Eudes Aholou</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.379222e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>Salvador SÃ¡nchez Ponce</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.940633e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Justo Wilmar Villar Viveros</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3.952155e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Ibrahim Amadou</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.108228e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>Anastasios Chatzigiovanis</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.021646e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AndrÃ©s TomÃ¡s Prieto Albert</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.379222e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1168 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        full_name  statistic_success_action_probs  \\\n",
       "158                ZoltÃ¡n Stieber                        1.000000   \n",
       "51             Ari Freyr SkÃºlason                        1.000000   \n",
       "695            Benjaloud Youssouf                        1.000000   \n",
       "75       Rui Pedro da Rocha Fonte                        1.000000   \n",
       "734             Jean-Eudes Aholou                        1.000000   \n",
       "...                           ...                             ...   \n",
       "841        Salvador SÃ¡nchez Ponce                        0.428571   \n",
       "88    Justo Wilmar Villar Viveros                        0.368421   \n",
       "1014               Ibrahim Amadou                        0.333333   \n",
       "676     Anastasios Chatzigiovanis                        0.333333   \n",
       "3      AndrÃ©s TomÃ¡s Prieto Albert                        0.300000   \n",
       "\n",
       "      statistic_success_action_among_players  statistic_success_total  \n",
       "158                                 0.000003             3.064937e-06  \n",
       "51                                  0.000011             1.072728e-05  \n",
       "695                                 0.000041             4.137665e-05  \n",
       "75                                  0.000012             1.225975e-05  \n",
       "734                                 0.000014             1.379222e-05  \n",
       "...                                      ...                      ...  \n",
       "841                                 0.000009             3.940633e-06  \n",
       "88                                  0.000011             3.952155e-06  \n",
       "1014                                0.000002             5.108228e-07  \n",
       "676                                 0.000003             1.021646e-06  \n",
       "3                                   0.000005             1.379222e-06  \n",
       "\n",
       "[1168 rows x 4 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD PROBABILITY SKILL DATASETS FOR PASSING EVENT\n",
    "DIRECTORY_PLAYER_SKILLS_PROBABILITIES_DATAS = \"data/model_xpass/xpass_player_skill_probs_dataset.csv\"\n",
    "\n",
    "xpass_player_skill_probs_df = pd.read_csv(DIRECTORY_PLAYER_SKILLS_PROBABILITIES_DATAS)\n",
    "xpass_player_skill_probs_df_copy = xpass_player_skill_probs_df.copy()\n",
    "\n",
    "# Scaling all feature columns in range (0, 1)\n",
    "xpass_player_skill_probs_df_copy[player_skills_column_included] = xpass_player_skill_probs_df_copy[player_skills_column_included] / 100\n",
    "\n",
    "# Filtering outliers data based on DBSCAN Plot Image (see generator code)\n",
    "epsilon = 0.525\n",
    "min_samples = 62\n",
    "dbscan = DBSCAN(eps=epsilon, min_samples=min_samples)\n",
    "dbscan.fit(xpass_player_skill_probs_df_copy[player_skills_column_included + [\"statistic_success_action_among_players\", \"statistic_success_action_probs\"]])\n",
    "labels = dbscan.labels_\n",
    "outliers_data = xpass_player_skill_probs_df_copy[labels == -1]\n",
    "\n",
    "xpass_player_skill_probs_df = xpass_player_skill_probs_df[~xpass_player_skill_probs_df.index.isin(outliers_data.index)]\n",
    "xpass_player_skill_probs_df[[\"full_name\", \"statistic_success_action_probs\", \"statistic_success_action_among_players\", \"statistic_success_total\"]].sort_values(by=\"statistic_success_action_probs\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 1 : Random Oversample Function\n",
    "def training_data_random_oversampled(X_train, Y_train, random_state):\n",
    "    ros = RandomOverSampler(random_state=random_state)\n",
    "    X_resampled, Y_resampled = ros.fit_resample(X_train, Y_train)\n",
    "    return (X_resampled, Y_resampled)\n",
    "\n",
    "# CASE 2 : Random Undersample Function\n",
    "def training_data_random_undersampled(X_train, Y_train, random_state):\n",
    "    rus = RandomUnderSampler(random_state=random_state)\n",
    "    X_resampled, Y_resampled = rus.fit_resample(X_train, Y_train)\n",
    "    return (X_resampled, Y_resampled)\n",
    "\n",
    "# CASE 3 : Random SMOTE Oversample Function\n",
    "def training_data_smote_oversampled(X_train, Y_train, random_state):\n",
    "    X_resampled, Y_resampled = SMOTE(random_state=random_state).fit_resample(X_train, Y_train)\n",
    "    return (X_resampled, Y_resampled)\n",
    "\n",
    "# V CASE 1 : Feature Selection - Pearson Coefficient\n",
    "def filter_columns_feature_selection_pearson(X_train, Y_train, columns_considered, threshold):\n",
    "    new_columns_after_selection = []\n",
    "    for _, skill in enumerate(columns_considered):\n",
    "        correlation_value, _ = pearsonr(X_train[skill], Y_train)\n",
    "        if correlation_value >= threshold:\n",
    "            new_columns_after_selection.append(skill)\n",
    "    return new_columns_after_selection\n",
    "\n",
    "def training_data_feature_selection_pearson(X_train, Y_train, columns_considered, threshold):\n",
    "    columns_selected = filter_columns_feature_selection_pearson(X_train, Y_train, columns_considered, threshold)\n",
    "    columns_omitted = [x for x in columns_considered if x not in columns_selected]\n",
    "    final_columns = [x for x in list(X_train.columns) if x not in columns_omitted]\n",
    "    print(final_columns)\n",
    "    return (X_train[final_columns], Y_train)\n",
    "\n",
    "# V CASE 2 : Feature Selection - Chi Square\n",
    "def filter_columns_feature_selection_chisquare(X_train, Y_train, columns_considered, num_of_features):\n",
    "    chi2_selector = SelectKBest(chi2, k=num_of_features) \n",
    "    df_feature = X_train[columns_considered]\n",
    "    chi2_selector.fit(df_feature, Y_train)\n",
    "    cols = chi2_selector.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_chisquare(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_selected = filter_columns_feature_selection_chisquare(X_train, Y_train, columns_considered, num_of_features)\n",
    "    columns_omitted = [x for x in columns_considered if x not in columns_selected]\n",
    "    final_columns = [x for x in list(X_train.columns) if x not in columns_omitted]\n",
    "    print(final_columns)\n",
    "    return (X_train[final_columns], Y_train)\n",
    "\n",
    "# V CASE 3 : Feature Selection - Mutual Information\n",
    "def filter_columns_feature_selection_mutualinf(X_train, Y_train, columns_considered, num_of_features):\n",
    "    mi_selector = SelectKBest(mutual_info_classif, k=num_of_features) \n",
    "    df_feature = X_train[columns_considered]\n",
    "    mi_selector.fit(df_feature, Y_train)\n",
    "    cols = mi_selector.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_mutualinf(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_selected = filter_columns_feature_selection_mutualinf(X_train, Y_train, columns_considered, num_of_features)\n",
    "    columns_omitted = [x for x in columns_considered if x not in columns_selected]\n",
    "    final_columns = [x for x in list(X_train.columns) if x not in columns_omitted]\n",
    "    print(final_columns)\n",
    "    return (X_train[final_columns], Y_train)\n",
    "\n",
    "# V CASE 4 : Feature Selection - mRMR Selection\n",
    "def filter_columns_feature_selection_mrmr(X_train, Y_train, columns_considered, num_of_features):\n",
    "    df_feature = X_train[columns_considered]\n",
    "    selected_features = mrmr_classif(X=df_feature, y=Y_train, K=num_of_features)\n",
    "    return selected_features\n",
    "\n",
    "def training_data_feature_selection_mrmr(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_selected = filter_columns_feature_selection_mrmr(X_train, Y_train, columns_considered, num_of_features)\n",
    "    columns_omitted = [x for x in columns_considered if x not in columns_selected]\n",
    "    final_columns = [x for x in list(X_train.columns) if x not in columns_omitted]\n",
    "    print(final_columns)\n",
    "    return (X_train[final_columns], Y_train)\n",
    "\n",
    "# X CASE 5 : Feature Selection - Sequential Forward Selection (SFS)\n",
    "def filter_columns_feature_selection_sfs(X_train, Y_train, columns_considered, num_of_features):\n",
    "    rf = RandomForestClassifier()\n",
    "    sfs = SequentialFeatureSelector(rf, n_features_to_select=num_of_features, direction='forward')\n",
    "    df_feature = X_train[columns_considered]\n",
    "    sfs.fit(df_feature, Y_train)\n",
    "    cols = sfs.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_sfs(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_selected = filter_columns_feature_selection_sfs(X_train, Y_train, columns_considered, num_of_features)\n",
    "    columns_omitted = [x for x in columns_considered if x not in columns_selected]\n",
    "    final_columns = [x for x in list(X_train.columns) if x not in columns_omitted]\n",
    "    print(final_columns)\n",
    "    return (X_train[final_columns], Y_train)\n",
    "\n",
    "# X CASE 6 : Feature Selection - Sequential Backward Elimination (SBE)\n",
    "def filter_columns_feature_selection_sbe(X_train, Y_train, columns_considered, num_of_features):\n",
    "    rf = RandomForestClassifier()\n",
    "    sfs = SequentialFeatureSelector(rf, n_features_to_select=num_of_features, direction='backward')\n",
    "    df_feature = X_train[columns_considered]\n",
    "    sfs.fit(df_feature, Y_train)\n",
    "    cols = sfs.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_sbe(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_selected = filter_columns_feature_selection_sbe(X_train, Y_train, columns_considered, num_of_features)\n",
    "    columns_omitted = [x for x in columns_considered if x not in columns_selected]\n",
    "    final_columns = [x for x in list(X_train.columns) if x not in columns_omitted]\n",
    "    print(final_columns)\n",
    "    return (X_train[final_columns], Y_train)\n",
    "\n",
    "# X CASE 7 : Feature Selection - Recursive Feature Elimination\n",
    "def filter_columns_feature_selection_rfe(X_train, Y_train, columns_considered, num_of_features):\n",
    "    estimator = LinearSVR()\n",
    "    selector = RFECV(estimator, step=1, cv=num_of_features)\n",
    "    df_feature = X_train[columns_considered]\n",
    "    selector.fit(df_feature, Y_train)\n",
    "    cols = selector.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_rfe(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_selected = filter_columns_feature_selection_rfe(X_train, Y_train, columns_considered, num_of_features)\n",
    "    columns_omitted = [x for x in columns_considered if x not in columns_selected]\n",
    "    final_columns = [x for x in list(X_train.columns) if x not in columns_omitted]\n",
    "    print(final_columns)\n",
    "    return (X_train[final_columns], Y_train)\n",
    "\n",
    "# V CASE 8 : Feature Selection - Random Forest Embedded (rfembedded)\n",
    "def filter_columns_feature_selection_rfembedded(X_train, Y_train, columns_considered, num_of_features):\n",
    "    estimator = RandomForestClassifier()\n",
    "    selector = SelectFromModel(estimator=estimator, max_features=num_of_features)\n",
    "    df_feature = X_train[columns_considered]\n",
    "    selector.fit(df_feature, Y_train)\n",
    "    cols = selector.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_rfembedded(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_selected = filter_columns_feature_selection_rfembedded(X_train, Y_train, columns_considered, num_of_features)\n",
    "    columns_omitted = [x for x in columns_considered if x not in columns_selected]\n",
    "    final_columns = [x for x in list(X_train.columns) if x not in columns_omitted]\n",
    "    print(final_columns)\n",
    "    return (X_train[final_columns], Y_train)\n",
    "\n",
    "# V CASE 9 : Feature Selection - LASSO\n",
    "def filter_columns_feature_selection_lasso(X_train, Y_train, columns_considered, num_of_features):\n",
    "    estimator = LogisticRegression(penalty='l2', C=0.5, solver='newton-cholesky')\n",
    "    selector = SelectFromModel(estimator=estimator, max_features=num_of_features)\n",
    "    df_feature = X_train[columns_considered]\n",
    "    selector.fit(df_feature, Y_train)\n",
    "    cols = selector.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_lasso(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_selected = filter_columns_feature_selection_lasso(X_train, Y_train, columns_considered, num_of_features)\n",
    "    columns_omitted = [x for x in columns_considered if x not in columns_selected]\n",
    "    final_columns = [x for x in list(X_train.columns) if x not in columns_omitted]\n",
    "    print(final_columns)\n",
    "    return (X_train[final_columns], Y_train)\n",
    "\n",
    "# CASE 1 : Train with model XGBRegressor\n",
    "def fit_and_train_with_model_xgbregressor(X_train, Y_train):\n",
    "    model = XGBRegressor(objective=\"reg:logistic\")\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model\n",
    "\n",
    "# CASE 2 : Train with model RandomForestRegressor\n",
    "def fit_and_train_with_model_rfregressor(X_train, Y_train):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model\n",
    "\n",
    "# CASE 3 : Train with model LogisticRegression\n",
    "def fit_and_train_with_model_logregression(X_train, Y_train, random_state_opt):\n",
    "    model = LogisticRegression(random_state=random_state_opt)\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model\n",
    "\n",
    "# CASE 4 : Train with model XGBClassifier\n",
    "def fit_and_train_with_model_xgbclassifier(X_train, Y_train):\n",
    "    # model = XGBClassifier(n_estimators=50, max_depth=3, n_jobs=-3, verbosity=1, enable_categorical=True)\n",
    "    model = XGBClassifier(objective=\"binary:logistic\")\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model\n",
    "\n",
    "# CASE 5 : Train with model Catboost Classifier \n",
    "def fit_and_train_with_model_catboostclassifier(X_train, Y_train):\n",
    "    # model = CatBoostClassifier(n_estimators=50, max_depth=3, verbose=1)\n",
    "    model = CatBoostClassifier()\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model\n",
    "\n",
    "# CASE 6 : Train with model RandomForest Classifier\n",
    "def fit_and_train_with_model_rfclassifier(X_train, Y_train):\n",
    "    # model = RandomForestClassifier(n_estimators=50, max_depth=3, n_jobs=-3, verbose=1)\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NEW CODES\n",
    "# # FEATURE PREPROCESSING BIG DATASETS AND CREATE XGBOOST MODEL\n",
    "# # 1. Change all numeric columns with MinMaxScaler\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# columns_minmax_scaler = [\"distance_pass\", \"num_opponent_in_path\", \"num_opponent_in_path_receiver\",\n",
    "#                         \"distance_opponent\", \"distance_receiver_opponent\",\n",
    "#                         \"num_opponent_0_and_45_before_midpoint_actor\",\n",
    "#                         \"num_opponent_0_and_45_after_midpoint_actor\",\n",
    "#                         \"num_opponent_0_and_45_before_midpoint_receiver\",\n",
    "#                         \"num_opponent_0_and_45_after_midpoint_receiver\"]\n",
    "# # Store Description for all Numeric Columns in External CSV\n",
    "# df_description_numeric = big_dataframe_xpass_model[columns_minmax_scaler].describe()\n",
    "# filename = 'xpass_description_numeric_data.csv'\n",
    "# directory_model = \"data/model_xpass_new/\"\n",
    "# df_description_numeric.to_csv(directory_model + filename)\n",
    "# # Preprocess to minmax scaler\n",
    "# big_dataframe_xpass_model[columns_minmax_scaler] = scaler.fit_transform(big_dataframe_xpass_model[columns_minmax_scaler])\n",
    "\n",
    "# # 2. Check if data is unbalanced. If it is unbalanced, then do method to oversize the sample\n",
    "# print(big_dataframe_xpass_model['result_id'].value_counts())\n",
    "\n",
    "# # 3. Remove dataframe instead of having result_id (0,1) --> (fail, success)\n",
    "# big_dataframe_xpass_model = big_dataframe_xpass_model[big_dataframe_xpass_model['result_id'].isin([0,1])]\n",
    "# print(big_dataframe_xpass_model['result_id'].value_counts())\n",
    "\n",
    "# # 4. Split train data and test data from Big Datasets\n",
    "# big_dataframe_xpass_model.reset_index(inplace=True, drop=True)\n",
    "# # sample_label_0 = big_dataframe_xpass_model[big_dataframe_xpass_model['result_id'] == 0]\n",
    "# # sample_label_1 = big_dataframe_xpass_model[big_dataframe_xpass_model['result_id'] == 1]\n",
    "# # big_dataframe_xpass_model_test = pd.concat([sample_label_0.sample(frac=0.2, random_state=42), sample_label_1.sample(frac=0.2, random_state=42)])\n",
    "# # big_dataframe_xpass_model = big_dataframe_xpass_model[~big_dataframe_xpass_model.index.isin(big_dataframe_xpass_model_test.index)]\n",
    "# # print(big_dataframe_xpass_model_test['result_id'].value_counts())\n",
    "# print(big_dataframe_xpass_model['result_id'].value_counts())\n",
    "\n",
    "# # filename = \"xpass_dataset_for_accuracy_test.csv\"\n",
    "# # directory_model = \"data/model_xpass_new/\"\n",
    "# # big_dataframe_xpass_model_test.to_csv(directory_model + filename)\n",
    "\n",
    "# all_feature_columns = columns_minmax_scaler\n",
    "# X_train = big_dataframe_xpass_model[all_feature_columns]\n",
    "# Y_train = big_dataframe_xpass_model[\"result_id\"]\n",
    "\n",
    "# # Empty dataframe for saving test result\n",
    "# empty_test_result = pd.DataFrame(columns=COLUMNS_EXPERIMENT_RESULT, index=[0])\n",
    "\n",
    "# for case_number in sorted(list(CONFIG_EXPERIMENTS_SCENARIO_MAP.keys())):\n",
    "#     include_skill_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"include_skill_opt\"]\n",
    "#     sampling_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"sampling_opt\"]\n",
    "#     feature_selection_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"feature_selection_opt\"]\n",
    "#     algorithm_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"algorithm_opt\"]\n",
    "#     random_state_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"random_state_opt\"]\n",
    "\n",
    "#     # 6. Filter out all player skills and attributes column if not include skill option\n",
    "#     if include_skill_opt == 0:\n",
    "#         only_featured_column = [column for column in features_column_included if column not in ['result_id', 'player_id', 'original_event_id']]\n",
    "#         X_train_filtered = X_train[only_featured_column]\n",
    "#     else:\n",
    "#         X_train_filtered = X_train\n",
    "\n",
    "#     # 7. Do oversampling/undersampling and feature selection at same time\n",
    "#     if sampling_opt == \"none\":\n",
    "#         X_resampled, Y_resampled = X_train_filtered, Y_train\n",
    "#     else:\n",
    "#         X_resampled, Y_resampled = globals()[\"training_data_\" + sampling_opt](X_train_filtered, Y_train, random_state_opt)\n",
    "#     if feature_selection_opt == \"none\":\n",
    "#         X_feature_sel, Y_feature_sel = X_resampled, Y_resampled\n",
    "#     else:\n",
    "#         if feature_selection_opt == \"pearson\":\n",
    "#             threshold = 0.5\n",
    "#             X_feature_sel, Y_feature_sel = globals()[\"training_data_feature_selection_\" + feature_selection_opt](X_resampled, Y_resampled, player_skills_column_included, threshold)\n",
    "#         else:\n",
    "#             num_of_features = 10\n",
    "#             X_feature_sel, Y_feature_sel = globals()[\"training_data_feature_selection_\" + feature_selection_opt](X_resampled, Y_resampled, player_skills_column_included, num_of_features)\n",
    "\n",
    "#     # 8. Do train_test_split on training data\n",
    "#     # X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_feature_sel, Y_feature_sel, test_size=0.2, random_state=random_state_opt)\n",
    "\n",
    "#     # 9. Train Model\n",
    "#     model = globals()[\"fit_and_train_with_model_\" + algorithm_opt](X_feature_sel, Y_feature_sel, random_state_opt)\n",
    "\n",
    "#     # # 10. Predict Testing Data\n",
    "#     # y_predict = model.predict(X_test_split)\n",
    "\n",
    "#     # # 11. Save test result experiment\n",
    "#     # if (USE_EVALUATION_METRIC_CLASSIFICATION):\n",
    "#     #     rec_score = recall_score(y_test_split, y_predict)\n",
    "#     #     prec_score = precision_score(y_test_split, y_predict)\n",
    "#     #     F1_score = f1_score(y_test_split, y_predict)\n",
    "#     #     acc_score = accuracy_score(y_test_split, y_predict)\n",
    "#     #     auc_score = roc_auc_score(y_test_split, y_predict)\n",
    "#     #     mcc_score = matthews_corrcoef(y_test_split, y_predict)\n",
    "#     #     brier_score = brier_score_loss(y_test_split, y_predict)\n",
    "#     #     log_loss_score = log_loss(y_test_split, y_predict)\n",
    "#     #     balanced_acc_score = balanced_accuracy_score(y_test_split, y_predict)\n",
    "#     # else:\n",
    "#     #     mean_squared_error_score = mean_squared_error(y_test_split, y_predict)\n",
    "#     #     root_mean_squared_error_score = mean_squared_error(y_test_split, y_predict, squared=False)\n",
    "#     #     auc_score = roc_auc_score(y_test_split, y_predict)\n",
    "#     #     brier_score = brier_score_loss(y_test_split, y_predict)\n",
    "#     #     log_loss_score = log_loss(y_test_split, y_predict)\n",
    "#     #     mean_absolute_error_score = mean_absolute_error(y_test_split, y_predict)\n",
    "#     #     r_squared_score = r2_score(y_test_split, y_predict)\n",
    "#     #     mean_absolute_percentage_error_score = mean_absolute_percentage_error(y_test_split, y_predict)\n",
    "\n",
    "#     maps_new_row = {}\n",
    "#     if USE_EVALUATION_METRIC_CLASSIFICATION:\n",
    "#         eval_metrics_column = COLUMNS_EVALUATION_METRIC_CLASSIFICATION\n",
    "#     else:\n",
    "#         eval_metrics_column = COLUMNS_EVALUATION_METRIC_REGRESSION\n",
    "#     for column in COLUMNS_EXPERIMENT_RESULT:\n",
    "#         if column not in eval_metrics_column:\n",
    "#             if column == \"case_number\":\n",
    "#                 maps_new_row[\"case_number\"] = case_number\n",
    "#             elif column in COLUMNS_SCENARIO_NAME:\n",
    "#                 maps_new_row[column] = globals()[column]\n",
    "#         else:\n",
    "#             maps_new_row[column] = globals()[column]     \n",
    "#     new_row = pd.DataFrame(maps_new_row, index=[0])\n",
    "#     empty_test_result = pd.concat([new_row, empty_test_result.loc[:]]).reset_index(drop=True)\n",
    "\n",
    "#     # 12. Save model to external file\n",
    "#     filename = f'xpass_model_case_{case_number}.sav'\n",
    "#     directory_model = \"data/model_xpass_new/\"\n",
    "#     pickle.dump(model, open(directory_model + filename, 'wb'))\n",
    "\n",
    "# # 13. Save test result experiment to external file\n",
    "# filename = 'xpass_test_model_experiment_result.csv'\n",
    "# directory_model = \"data/model_xpass_new/\"\n",
    "# empty_test_result.to_csv(directory_model + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OLD CODES (DON'T USE !!!!!!!)\n",
    "# # FEATURE PREPROCESSING BIG DATASETS AND CREATE XGBOOST MODEL\n",
    "# # 1. Change all numeric columns with MinMaxScaler\n",
    "# scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "# # columns_minmax_scaler = [\"start_x\", \"start_y\", \"end_x\", \"end_y\", \"distance_pass\", \"distance_sideline\", \n",
    "# #                         \"distance_goal\", \"distance_receiver_sideline\", \"distance_receiver_goal\", \"angle_pass\",\n",
    "# #                         \"distance_opponent\", \"num_opponent_closer_goal\", \"distance_receiver_opponent\", \n",
    "# #                         \"num_opponent_closer_goal_receiver\", \"num_opponent_in_path\", \"num_opponent_in_path_receiver\"]\n",
    "# columns_minmax_scaler = [\"distance_pass\", \"num_opponent_in_path\", \"num_opponent_in_path_receiver\",\n",
    "#                         \"num_opponent_0_and_45_before_midpoint_actor\",\n",
    "#                         \"num_opponent_0_and_45_after_midpoint_actor\",\n",
    "#                         # \"num_opponent_45_and_90_before_midpoint_actor\",\n",
    "#                         # \"num_opponent_45_and_90_after_midpoint_actor\",\n",
    "#                         # \"num_opponent_90_and_135_before_midpoint_actor\",\n",
    "#                         # \"num_opponent_90_and_135_after_midpoint_actor\",\n",
    "#                         # \"num_opponent_135_and_180_before_midpoint_actor\",\n",
    "#                         # \"num_opponent_135_and_180_after_midpoint_actor\",\n",
    "#                         \"num_opponent_0_and_45_before_midpoint_receiver\",\n",
    "#                         \"num_opponent_0_and_45_after_midpoint_receiver\",\n",
    "#                         # \"num_opponent_45_and_90_before_midpoint_receiver\",\n",
    "#                         # \"num_opponent_45_and_90_after_midpoint_receiver\",\n",
    "#                         # \"num_opponent_90_and_135_before_midpoint_receiver\",\n",
    "#                         # \"num_opponent_90_and_135_after_midpoint_receiver\",\n",
    "#                         # \"num_opponent_135_and_180_before_midpoint_receiver\",\n",
    "#                         # \"num_opponent_135_and_180_after_midpoint_receiver\"\n",
    "#                         ]\n",
    "# # Store Description for all Numeric Columns in External CSV\n",
    "# df_description_numeric = big_dataframe_xpass_model[columns_minmax_scaler].describe()\n",
    "# filename = 'xpass_description_numeric_data.csv'\n",
    "# directory_model = \"data/model_xpass_new/\"\n",
    "# df_description_numeric.to_csv(directory_model + filename)\n",
    "# # Preprocess to minmax scaler\n",
    "# # big_dataframe_xpass_model[columns_minmax_scaler] = scaler.fit_transform(big_dataframe_xpass_model[columns_minmax_scaler])\n",
    "\n",
    "# # 2. Check if data is unbalanced. If it is unbalanced, then do method to oversize the sample\n",
    "# print(big_dataframe_xpass_model['result_id'].value_counts())\n",
    "\n",
    "# # 3. Change result_id label into float64 type\n",
    "# # big_dataframe_xpass_model['result_id'] = big_dataframe_xpass_model['result_id'].astype('float64')\n",
    "\n",
    "# # 4. Remove dataframe instead of having result_id (0,1) --> (fail, success)\n",
    "# big_dataframe_xpass_model = big_dataframe_xpass_model[big_dataframe_xpass_model['result_id'].isin([0,1])]\n",
    "# print(big_dataframe_xpass_model['result_id'].value_counts())\n",
    "\n",
    "# # 5. Split train data and test data from Big Datasets\n",
    "# big_dataframe_xpass_model.reset_index(inplace=True, drop=True)\n",
    "# sample_label_0 = big_dataframe_xpass_model[big_dataframe_xpass_model['result_id'] == 0]\n",
    "# sample_label_1 = big_dataframe_xpass_model[big_dataframe_xpass_model['result_id'] == 1]\n",
    "# big_dataframe_xpass_model_test = pd.concat([sample_label_0.sample(frac=0.2, random_state=42), sample_label_1.sample(frac=0.2, random_state=42)])\n",
    "# big_dataframe_xpass_model = big_dataframe_xpass_model[~big_dataframe_xpass_model.index.isin(big_dataframe_xpass_model_test.index)]\n",
    "# print(big_dataframe_xpass_model_test['result_id'].value_counts())\n",
    "# print(big_dataframe_xpass_model['result_id'].value_counts())\n",
    "\n",
    "# filename = \"xpass_dataset_for_accuracy_test.csv\"\n",
    "# directory_model = \"data/model_xpass_new/\"\n",
    "# big_dataframe_xpass_model_test.to_csv(directory_model + filename)\n",
    "\n",
    "# all_feature_columns = columns_minmax_scaler\n",
    "# X_train = big_dataframe_xpass_model[all_feature_columns]\n",
    "# Y_train = big_dataframe_xpass_model[\"result_id\"]\n",
    "\n",
    "# # Empty dataframe for saving test result\n",
    "# empty_test_result = pd.DataFrame(columns=COLUMNS_EXPERIMENT_RESULT, index=[0])\n",
    "\n",
    "# for case_number in sorted(list(CONFIG_EXPERIMENTS_SCENARIO_MAP.keys())):\n",
    "#     include_skill_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"include_skill_opt\"]\n",
    "#     sampling_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"sampling_opt\"]\n",
    "#     feature_selection_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"feature_selection_opt\"]\n",
    "#     algorithm_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"algorithm_opt\"]\n",
    "#     random_state_opt = CONFIG_EXPERIMENTS_SCENARIO_MAP[case_number][\"random_state_opt\"]\n",
    "\n",
    "#     # 6. Filter out all player skills and attributes column if not include skill option\n",
    "#     if include_skill_opt == 0:\n",
    "#         only_featured_column = [column for column in features_column_included if column not in ['result_id', 'player_id', 'original_event_id']]\n",
    "#         X_train_filtered = X_train[only_featured_column]\n",
    "#     else:\n",
    "#         X_train_filtered = X_train\n",
    "\n",
    "#     # 7. Do oversampling/undersampling and feature selection at same time\n",
    "#     if sampling_opt == \"none\":\n",
    "#         X_resampled, Y_resampled = X_train_filtered, Y_train\n",
    "#     else:\n",
    "#         X_resampled, Y_resampled = globals()[\"training_data_\" + sampling_opt](X_train_filtered, Y_train, random_state_opt)\n",
    "#     if feature_selection_opt == \"none\":\n",
    "#         X_feature_sel, Y_feature_sel = X_resampled, Y_resampled\n",
    "#     else:\n",
    "#         if feature_selection_opt == \"pearson\":\n",
    "#             threshold = 0.5\n",
    "#             X_feature_sel, Y_feature_sel = globals()[\"training_data_feature_selection_\" + feature_selection_opt](X_resampled, Y_resampled, player_skills_column_included, threshold)\n",
    "#         else:\n",
    "#             num_of_features = 10\n",
    "#             X_feature_sel, Y_feature_sel = globals()[\"training_data_feature_selection_\" + feature_selection_opt](X_resampled, Y_resampled, player_skills_column_included, num_of_features)\n",
    "\n",
    "#     # 8. Do train_test_split on training data\n",
    "#     # X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_feature_sel, Y_feature_sel, test_size=0.2, random_state=random_state_opt)\n",
    "\n",
    "#     # 9. Train Model\n",
    "#     model = globals()[\"fit_and_train_with_model_\" + algorithm_opt](X_feature_sel, Y_feature_sel)\n",
    "\n",
    "#     # # 10. Predict Testing Data\n",
    "#     # y_predict = model.predict(X_test_split)\n",
    "\n",
    "#     # # 11. Save test result experiment\n",
    "#     # if (USE_EVALUATION_METRIC_CLASSIFICATION):\n",
    "#     #     rec_score = recall_score(y_test_split, y_predict)\n",
    "#     #     prec_score = precision_score(y_test_split, y_predict)\n",
    "#     #     F1_score = f1_score(y_test_split, y_predict)\n",
    "#     #     acc_score = accuracy_score(y_test_split, y_predict)\n",
    "#     #     auc_score = roc_auc_score(y_test_split, y_predict)\n",
    "#     #     mcc_score = matthews_corrcoef(y_test_split, y_predict)\n",
    "#     #     brier_score = brier_score_loss(y_test_split, y_predict)\n",
    "#     #     log_loss_score = log_loss(y_test_split, y_predict)\n",
    "#     #     balanced_acc_score = balanced_accuracy_score(y_test_split, y_predict)\n",
    "#     # else:\n",
    "#     #     mean_squared_error_score = mean_squared_error(y_test_split, y_predict)\n",
    "#     #     root_mean_squared_error_score = mean_squared_error(y_test_split, y_predict, squared=False)\n",
    "#     #     auc_score = roc_auc_score(y_test_split, y_predict)\n",
    "#     #     brier_score = brier_score_loss(y_test_split, y_predict)\n",
    "#     #     log_loss_score = log_loss(y_test_split, y_predict)\n",
    "#     #     mean_absolute_error_score = mean_absolute_error(y_test_split, y_predict)\n",
    "#     #     r_squared_score = r2_score(y_test_split, y_predict)\n",
    "#     #     mean_absolute_percentage_error_score = mean_absolute_percentage_error(y_test_split, y_predict)\n",
    "\n",
    "#     maps_new_row = {}\n",
    "#     if USE_EVALUATION_METRIC_CLASSIFICATION:\n",
    "#         eval_metrics_column = COLUMNS_EVALUATION_METRIC_CLASSIFICATION\n",
    "#     else:\n",
    "#         eval_metrics_column = COLUMNS_EVALUATION_METRIC_REGRESSION\n",
    "#     for column in COLUMNS_EXPERIMENT_RESULT:\n",
    "#         if column not in eval_metrics_column:\n",
    "#             if column == \"case_number\":\n",
    "#                 maps_new_row[\"case_number\"] = case_number\n",
    "#             elif column in COLUMNS_SCENARIO_NAME:\n",
    "#                 maps_new_row[column] = globals()[column]\n",
    "#         else:\n",
    "#             maps_new_row[column] = globals()[column]     \n",
    "#     new_row = pd.DataFrame(maps_new_row, index=[0])\n",
    "#     empty_test_result = pd.concat([new_row, empty_test_result.loc[:]]).reset_index(drop=True)\n",
    "\n",
    "#     # 12. Save model to external file\n",
    "#     filename = f'xpass_model_case_{case_number}.sav'\n",
    "#     directory_model = \"data/model_xpass_new/\"\n",
    "#     pickle.dump(model, open(directory_model + filename, 'wb'))\n",
    "\n",
    "# # 13. Save test result experiment to external file\n",
    "# filename = 'xpass_test_model_experiment_result.csv'\n",
    "# directory_model = \"data/model_xpass_new/\"\n",
    "# empty_test_result.to_csv(directory_model + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 1 : Feature Selection for Regression - Mutual Information\n",
    "def filter_columns_feature_selection_reg_mutualinf(X_train, Y_train, columns_considered, num_of_features):\n",
    "    mi_selector = SelectKBest(score_func=partial(mutual_info_regression, random_state=0), k=num_of_features)\n",
    "    df_feature = X_train[columns_considered]\n",
    "    mi_selector.fit(df_feature, Y_train)\n",
    "    cols = mi_selector.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_reg_mutualinf(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_selected = filter_columns_feature_selection_reg_mutualinf(X_train, Y_train, columns_considered, num_of_features)\n",
    "    columns_omitted = [x for x in columns_considered if x not in columns_selected]\n",
    "    final_columns = [x for x in list(X_train.columns) if x not in columns_omitted]\n",
    "    print(final_columns)\n",
    "    return (X_train[final_columns], Y_train)\n",
    "\n",
    "# CASE 2 : Feature Selection for Regression - Pearson Coefficient\n",
    "def filter_columns_feature_selection_reg_pearson(X_train, Y_train, columns_considered, num_of_features):\n",
    "    mi_selector = SelectKBest(f_regression, k=num_of_features) \n",
    "    df_feature = X_train[columns_considered]\n",
    "    mi_selector.fit(df_feature, Y_train)\n",
    "    cols = mi_selector.get_support(indices=True)\n",
    "    df_selected_features = df_feature.iloc[:,cols]\n",
    "    return df_selected_features.columns\n",
    "\n",
    "def training_data_feature_selection_reg_pearson(X_train, Y_train, columns_considered, num_of_features):\n",
    "    columns_selected = filter_columns_feature_selection_reg_pearson(X_train, Y_train, columns_considered, num_of_features)\n",
    "    columns_omitted = [x for x in columns_considered if x not in columns_selected]\n",
    "    final_columns = [x for x in list(X_train.columns) if x not in columns_omitted]\n",
    "    print(final_columns)\n",
    "    return (X_train[final_columns], Y_train)\n",
    "\n",
    "# CASE 1 : Train with model LinearRegressor\n",
    "def fit_and_train_with_model_linearregressor(X_train, Y_train):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CREATE REGRESSION XGBOOST MODEL FOR PLAYER SKILL PROBABILITIES DATASET \n",
    "# # 1. Change all numeric columns with MinMaxScaler\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# columns_minmax_scaler = player_skills_column_included + player_attribute_column_included + [\"statistic_success_action_probs\"]\n",
    "# # Store Description for all Numeric Columns in External CSV\n",
    "# df_description_numeric = xpass_player_skill_probs_df[columns_minmax_scaler].describe()\n",
    "# filename = 'xpass_skill_probs_description_numeric_data.csv'\n",
    "# directory_model = \"data/model_xpass_new/\"\n",
    "# df_description_numeric.to_csv(directory_model + filename)\n",
    "# # Preprocess to minmax scaler\n",
    "# xpass_player_skill_probs_df[columns_minmax_scaler] = scaler.fit_transform(xpass_player_skill_probs_df[columns_minmax_scaler])\n",
    "\n",
    "# # 2. Change type of minmax column as float64\n",
    "# xpass_player_skill_probs_df[columns_minmax_scaler] = xpass_player_skill_probs_df[columns_minmax_scaler].astype('float64')\n",
    "\n",
    "# # 3. Split train data and test data from Big Datasets\n",
    "# all_feature_columns = player_skills_column_included + player_attribute_column_included\n",
    "# X_train = xpass_player_skill_probs_df[all_feature_columns]\n",
    "# Y_train = xpass_player_skill_probs_df[\"statistic_success_action_probs\"]\n",
    "\n",
    "# # Empty dataframe for saving test result\n",
    "# empty_test_result = pd.DataFrame(columns=COLUMNS_EXPERIMENT_RESULT_PLAYER_SKILL_PROBS, index=[0])\n",
    "\n",
    "# for case_number in sorted(list(CONFIG_EXPERIMENTS_SKILL_PROBS_SCENARIO_MAP.keys())):\n",
    "#     feature_selection_opt = CONFIG_EXPERIMENTS_SKILL_PROBS_SCENARIO_MAP[case_number][\"feature_selection_opt\"]\n",
    "#     random_state_opt = CONFIG_EXPERIMENTS_SKILL_PROBS_SCENARIO_MAP[case_number][\"random_state_opt\"]\n",
    "\n",
    "#     # 4. Do feature selection on train data\n",
    "#     num_of_features = 10\n",
    "#     X_feature_sel, Y_feature_sel = globals()[\"training_data_feature_selection_reg_\" + feature_selection_opt](X_train, Y_train, player_skills_column_included, num_of_features)\n",
    "\n",
    "#     # # 5. Do train_test_split on training data\n",
    "#     # X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_feature_sel, Y_feature_sel, test_size=0.2, random_state=random_state_opt)\n",
    "\n",
    "#     # 6. Train Model with XGBRegressor\n",
    "#     model = fit_and_train_with_model_linearregressor(X_feature_sel, Y_feature_sel)\n",
    "\n",
    "#     # # 7. Predict Testing Data\n",
    "#     # y_predict = model.predict(X_test_split)\n",
    "\n",
    "#     # # 8. Save test result experiment\n",
    "#     # mean_squared_error_score = mean_squared_error(y_test_split, y_predict)\n",
    "#     # root_mean_squared_error_score = mean_squared_error(y_test_split, y_predict, squared=False)\n",
    "#     # mean_absolute_error_score = mean_absolute_error(y_test_split, y_predict)\n",
    "#     # r_squared_score = r2_score(y_test_split, y_predict)\n",
    "#     # mean_absolute_percentage_error_score = mean_absolute_percentage_error(y_test_split, y_predict)\n",
    "\n",
    "#     maps_new_row = {}\n",
    "#     eval_metrics_column = COLUMNS_EVALUATION_METRIC_REGRESSION\n",
    "#     for column in COLUMNS_EXPERIMENT_RESULT_PLAYER_SKILL_PROBS:\n",
    "#         if column not in eval_metrics_column:\n",
    "#             if column == \"feature_selection_opt\":\n",
    "#                 maps_new_row[\"feature_selection_opt\"] = feature_selection_opt\n",
    "#             elif column == \"random_state_opt\":\n",
    "#                 maps_new_row[\"random_state_opt\"] = random_state_opt\n",
    "#             elif column == \"case_number\":\n",
    "#                 maps_new_row[\"case_number\"] = case_number\n",
    "#         else:\n",
    "#             maps_new_row[column] = globals()[column]     \n",
    "#     new_row = pd.DataFrame(maps_new_row, index=[0])\n",
    "#     empty_test_result = pd.concat([new_row, empty_test_result.loc[:]]).reset_index(drop=True)\n",
    "\n",
    "#     # 9. Save model to external file\n",
    "#     filename = f'xpass_player_skill_probs_model_case_{case_number}.sav'\n",
    "#     directory_model = \"data/model_xpass_new/\"\n",
    "#     pickle.dump(model, open(directory_model + filename, 'wb'))\n",
    "\n",
    "#     case_number += 1\n",
    "\n",
    "# # 10. Save test result experiment to external file\n",
    "# filename = 'xpass_player_skill_probs_model_experiment_result.csv'\n",
    "# directory_model = \"data/model_xpass_new/\"\n",
    "# empty_test_result.to_csv(directory_model + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CALCULATE REAL ACCURACY OF SUCCESSFUL PASSES BASED ON THRESHOLD\n",
    "# CASE_NUMBER_LIST_FOR_AVAILABLE_XPASS_MODEL = [6]\n",
    "# CASE_NUMBER_LIST_FOR_AVAILABLE_XPASS_SKILL_PROBS_MODEL = [1]\n",
    "# LIST_DEFINED_THRESHOLD = [0.09352988885334529]\n",
    "# MAPS_ACCURACY_SCORE_XPASS_MODEL = {}\n",
    "# MAPS_PRECISION_SCORE_XPASS_MODEL = {}\n",
    "# MAPS_RECALL_SCORE_XPASS_MODEL = {}\n",
    "# MAPS_F_SCORE_XPASS_MODEL = {}\n",
    "# MAPS_XPASS_DIFFICULTY_VALUES_BY_ORIGINAL_EVENT_ID = {}\n",
    "# MAPS_XPASS_SKILL_PROBS_VALUES_BY_PLAYER_ID = {}\n",
    "# COLUMNS_XPASS_FINAL_ACCURACY_RESULT = [\n",
    "#     \"case_number_xpass_model\",\n",
    "#     \"case_number_xpass_skill_probs_model\",\n",
    "#     \"accuracy_without_skill\",\n",
    "#     \"accuracy_with_player_skill\",\n",
    "#     \"accuracy_difference\",\n",
    "#     \"precision_without_skill\",\n",
    "#     \"precision_with_player_skill\",\n",
    "#     \"precision_difference\",\n",
    "#     \"recall_without_skill\",\n",
    "#     \"recall_with_player_skill\",\n",
    "#     \"recall_difference\",\n",
    "#     \"f_score_without_skill\",\n",
    "#     \"f_score_with_player_skill\",\n",
    "#     \"f_score_difference\"\n",
    "# ]\n",
    "# COLUMNS_XPASS_CONFUSION_MATRIX_DISTRIBUTION_RESULT = [\n",
    "#     \"case_number_xpass_model\",\n",
    "#     \"case_number_xpass_skill_probs_model\",\n",
    "#     \"true_positive\",\n",
    "#     \"true_negative\",\n",
    "#     \"false_positive\",\n",
    "#     \"false_negative\"\n",
    "# ]\n",
    "# DIRECTORY_MODEL = \"data/model_xpass_new/\"\n",
    "# FILENAME_DATA_TEST = \"xpass_dataset_for_accuracy_test.csv\"\n",
    "\n",
    "# # Difficulty Value : Change all numeric columns with StandardScaler\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# columns_minmax_scaler = [\"distance_pass\", \"num_opponent_in_path\", \"num_opponent_in_path_receiver\",\n",
    "#                         \"distance_opponent\", \"distance_receiver_opponent\",\n",
    "#                         \"num_opponent_0_and_45_before_midpoint_actor\",\n",
    "#                         \"num_opponent_0_and_45_after_midpoint_actor\",\n",
    "#                         \"num_opponent_0_and_45_before_midpoint_receiver\",\n",
    "#                         \"num_opponent_0_and_45_after_midpoint_receiver\"]\n",
    "# big_dataframe_xpass_model[columns_minmax_scaler] = scaler.fit_transform(big_dataframe_xpass_model[columns_minmax_scaler])\n",
    "# big_dataframe_xpass_model = big_dataframe_xpass_model[big_dataframe_xpass_model['result_id'].isin([0,1])]\n",
    "\n",
    "# # Player Skill Probabilities : Change all numeric columns with MinMaxScaler\n",
    "# scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "# columns_minmax_scaler = player_skills_column_included + player_attribute_column_included + [\"statistic_success_action_probs\"]\n",
    "# xpass_player_skill_probs_df[columns_minmax_scaler] = scaler.fit_transform(xpass_player_skill_probs_df[columns_minmax_scaler])\n",
    "\n",
    "# xpass_data_test = big_dataframe_xpass_model\n",
    "\n",
    "# for threshold in LIST_DEFINED_THRESHOLD:\n",
    "#     DEFINED_THRESHOLD = threshold\n",
    "#     # Construct maps xpass difficulty values and maps accuracy score xpass model\n",
    "#     for case_number_xpass_model in CASE_NUMBER_LIST_FOR_AVAILABLE_XPASS_MODEL:\n",
    "#         # Loads xpass difficulty model\n",
    "#         filename_xpass_model = f'xpass_model_case_{case_number_xpass_model}.sav'\n",
    "#         xpass_model = pickle.load(open(DIRECTORY_MODEL + filename_xpass_model, 'rb'))\n",
    "#         feature_names_xpass_model = xpass_model.feature_names_in_\n",
    "\n",
    "#         actual_result_ids = pd.Series(xpass_data_test[\"result_id\"]).tolist()\n",
    "#         original_event_ids = pd.Series(xpass_data_test[\"original_event_id\"]).tolist()\n",
    "#         player_ids = pd.Series(xpass_data_test[\"player_id\"]).tolist()\n",
    "#         xpass_train_data = xpass_data_test[feature_names_xpass_model]\n",
    "#         xpass_difficulty_value = [p[1] for p in xpass_model.predict_proba(xpass_train_data)]\n",
    "        \n",
    "#         TP_counter, FP_counter, FN_counter, TN_counter = 0, 0, 0, 0\n",
    "#         for idx, event_id in enumerate(original_event_ids):\n",
    "#             actual_result_id = actual_result_ids[idx]\n",
    "#             xpass_difficulty_this_value = xpass_difficulty_value[idx]\n",
    "#             player_id = player_ids[idx]\n",
    "#             player_data = xpass_player_skill_probs_df[xpass_player_skill_probs_df[\"player_id\"] == player_id]\n",
    "#             if (not player_data.empty):\n",
    "#                 MAPS_XPASS_DIFFICULTY_VALUES_BY_ORIGINAL_EVENT_ID[(case_number_xpass_model, event_id)] = xpass_difficulty_this_value\n",
    "#                 predicted_result_id = 1 if xpass_difficulty_this_value > DEFINED_THRESHOLD else 0\n",
    "#                 if (actual_result_id == 1) and (predicted_result_id == 1):\n",
    "#                     TP_counter += 1\n",
    "#                 elif (actual_result_id == 0) and (predicted_result_id == 1):\n",
    "#                     FP_counter += 1\n",
    "#                 elif (actual_result_id == 1) and (predicted_result_id == 0):\n",
    "#                     FN_counter += 1\n",
    "#                 elif (actual_result_id == 0) and (predicted_result_id == 0):\n",
    "#                     TN_counter += 1\n",
    "#         MAPS_ACCURACY_SCORE_XPASS_MODEL[case_number_xpass_model] = (TP_counter + TN_counter) / (TP_counter + TN_counter + FP_counter + FN_counter)\n",
    "#         MAPS_PRECISION_SCORE_XPASS_MODEL[case_number_xpass_model] = (TP_counter / (TP_counter + FP_counter)) if (TP_counter + FP_counter) > 0 else 0\n",
    "#         MAPS_RECALL_SCORE_XPASS_MODEL[case_number_xpass_model] = TP_counter / (TP_counter + FN_counter)\n",
    "#         MAPS_F_SCORE_XPASS_MODEL[case_number_xpass_model] = TP_counter / (TP_counter + 0.5 * (FP_counter + FN_counter))\n",
    "\n",
    "#     # Construct maps xpass player skill probabilities value\n",
    "#     unique_player_ids = list(set(pd.Series(xpass_data_test[\"player_id\"]).tolist()))\n",
    "#     for case_number_xpass_skill_probs_model in CASE_NUMBER_LIST_FOR_AVAILABLE_XPASS_SKILL_PROBS_MODEL:\n",
    "#         # Load xpass player skill probs model\n",
    "#         filename_xpass_skill_probs_model = f'xpass_player_skill_probs_model_case_{case_number_xpass_skill_probs_model}.sav'\n",
    "#         xpass_skill_probs_model = pickle.load(open(DIRECTORY_MODEL + filename_xpass_skill_probs_model, 'rb'))\n",
    "#         # feature_names_xpass_skill_probs_model = xpass_skill_probs_model.get_booster().feature_names\n",
    "#         feature_names_xpass_skill_probs_model = xpass_skill_probs_model.feature_names_in_\n",
    "\n",
    "#         for player_id in unique_player_ids:\n",
    "#             xpass_skill_train_data = xpass_player_skill_probs_df[xpass_player_skill_probs_df[\"player_id\"] == player_id][feature_names_xpass_skill_probs_model]\n",
    "#             if (not xpass_skill_train_data.empty):\n",
    "#                 xpass_skill_value = xpass_skill_probs_model.predict(xpass_skill_train_data)[0]\n",
    "#                 if (xpass_skill_value > 1.0):\n",
    "#                     xpass_skill_value = 1.0\n",
    "#                 elif (xpass_skill_value < 0.0):\n",
    "#                     xpass_skill_value = 0.0\n",
    "#                 MAPS_XPASS_SKILL_PROBS_VALUES_BY_PLAYER_ID[(case_number_xpass_skill_probs_model, player_id)] = xpass_skill_value\n",
    "\n",
    "#     # Final Calculation and Saving Test Result\n",
    "#     empty_test_result = pd.DataFrame(columns=COLUMNS_XPASS_FINAL_ACCURACY_RESULT, index=[0])\n",
    "#     empty_confusion_matrix_result = pd.DataFrame(columns=COLUMNS_XPASS_CONFUSION_MATRIX_DISTRIBUTION_RESULT, index=[0])\n",
    "\n",
    "#     for case_number_xpass_model in CASE_NUMBER_LIST_FOR_AVAILABLE_XPASS_MODEL:\n",
    "#         for case_number_xpass_skill_probs_model in CASE_NUMBER_LIST_FOR_AVAILABLE_XPASS_SKILL_PROBS_MODEL:\n",
    "#             TP_counter, FP_counter, FN_counter, TN_counter = 0, 0, 0, 0\n",
    "#             for _, xpass_row_data in xpass_data_test.iterrows():\n",
    "#                 actual_result_id = xpass_row_data[\"result_id\"]\n",
    "#                 original_event_id = xpass_row_data[\"original_event_id\"]\n",
    "#                 related_player_id = xpass_row_data[\"player_id\"]\n",
    "#                 xpass_skill_train_data = xpass_player_skill_probs_df[xpass_player_skill_probs_df[\"player_id\"] == related_player_id][feature_names_xpass_skill_probs_model]\n",
    "#                 if (not xpass_skill_train_data.empty):\n",
    "#                     xpass_difficulty_value = MAPS_XPASS_DIFFICULTY_VALUES_BY_ORIGINAL_EVENT_ID[(case_number_xpass_model, original_event_id)]\n",
    "#                     xpass_skill_value = MAPS_XPASS_SKILL_PROBS_VALUES_BY_PLAYER_ID[(case_number_xpass_skill_probs_model, related_player_id)]\n",
    "#                     predicted_result_id = 1 if (xpass_difficulty_value * xpass_skill_value) >= DEFINED_THRESHOLD else 0\n",
    "#                     if (actual_result_id == 1) and (predicted_result_id == 1):\n",
    "#                         TP_counter += 1\n",
    "#                     elif (actual_result_id == 0) and (predicted_result_id == 1):\n",
    "#                         FP_counter += 1\n",
    "#                     elif (actual_result_id == 1) and (predicted_result_id == 0):\n",
    "#                         FN_counter += 1\n",
    "#                     elif (actual_result_id == 0) and (predicted_result_id == 0):\n",
    "#                         TN_counter += 1\n",
    "\n",
    "#             print(f'True Positive : {TP_counter} ; False Positive : {FP_counter} ; False Negative : {FN_counter} ; True Negative : {TN_counter}')\n",
    "#             accuracy_with_player_skill = (TP_counter + TN_counter) / (TP_counter + TN_counter + FP_counter + FN_counter)\n",
    "#             accuracy_without_player_skill = MAPS_ACCURACY_SCORE_XPASS_MODEL[case_number_xpass_model]\n",
    "#             precision_with_player_skill = (TP_counter / (TP_counter + FP_counter)) if (TP_counter + FP_counter) > 0 else 0\n",
    "#             precision_without_player_skill = MAPS_PRECISION_SCORE_XPASS_MODEL[case_number_xpass_model]\n",
    "#             recall_with_player_skill = (TP_counter / (TP_counter + FN_counter)) if (TP_counter + FN_counter) > 0 else 0\n",
    "#             recall_without_player_skill = MAPS_RECALL_SCORE_XPASS_MODEL[case_number_xpass_model]\n",
    "#             f_score_with_player_skill = (2 * precision_with_player_skill * recall_with_player_skill) / (precision_with_player_skill + recall_with_player_skill)\n",
    "#             f_score_without_player_skill = MAPS_F_SCORE_XPASS_MODEL[case_number_xpass_model]\n",
    "            \n",
    "#             maps_new_row = {\n",
    "#                 \"case_number_xpass_model\" : case_number_xpass_model,\n",
    "#                 \"case_number_xpass_skill_probs_model\" : case_number_xpass_skill_probs_model,\n",
    "#                 \"accuracy_without_skill\" : accuracy_without_player_skill,\n",
    "#                 \"accuracy_with_player_skill\" : accuracy_with_player_skill,\n",
    "#                 \"accuracy_difference\" : (accuracy_without_player_skill - accuracy_with_player_skill),\n",
    "#                 \"precision_without_skill\" : precision_without_player_skill,\n",
    "#                 \"precision_with_player_skill\" : precision_with_player_skill,\n",
    "#                 \"precision_difference\" : (precision_without_player_skill - precision_with_player_skill),\n",
    "#                 \"recall_without_skill\" : recall_without_player_skill,\n",
    "#                 \"recall_with_player_skill\" : recall_with_player_skill,\n",
    "#                 \"recall_difference\" : (recall_without_player_skill - recall_with_player_skill),\n",
    "#                 \"f_score_without_skill\" : f_score_without_player_skill,\n",
    "#                 \"f_score_with_player_skill\" : f_score_with_player_skill,\n",
    "#                 \"f_score_difference\" : (f_score_without_player_skill - f_score_with_player_skill)\n",
    "#             }\n",
    "#             new_row = pd.DataFrame(maps_new_row, index=[0])\n",
    "#             empty_test_result = pd.concat([new_row, empty_test_result.loc[:]]).reset_index(drop=True)\n",
    "\n",
    "#             maps_new_row_confusion_matrix = {\n",
    "#                 \"case_number_xpass_model\" : case_number_xpass_model,\n",
    "#                 \"case_number_xpass_skill_probs_model\" : case_number_xpass_skill_probs_model,\n",
    "#                 \"true_positive\" : TP_counter,\n",
    "#                 \"true_negative\" : TN_counter,\n",
    "#                 \"false_positive\" : FP_counter,\n",
    "#                 \"false_negative\" : FN_counter\n",
    "#             }\n",
    "#             new_row_confusion_matrix = pd.DataFrame(maps_new_row_confusion_matrix, index=[0])\n",
    "#             empty_confusion_matrix_result = pd.concat([new_row_confusion_matrix, empty_confusion_matrix_result.loc[:]]).reset_index(drop=True)\n",
    "            \n",
    "#     filename_experiment_result = f'xpass_final_accuracy_with_threshold_{DEFINED_THRESHOLD}.csv'\n",
    "#     empty_test_result.to_csv(DIRECTORY_MODEL + filename_experiment_result)\n",
    "#     filename_experiment_confusion_matrix_result = f'xpass_confusion_matrix_with_threshold_{DEFINED_THRESHOLD}.csv'\n",
    "#     empty_confusion_matrix_result.to_csv(DIRECTORY_MODEL + filename_experiment_confusion_matrix_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PLOT PRECISION-RECALL CURVE\n",
    "# CASE_NUMBER_LIST_FOR_AVAILABLE_XPASS_MODEL = [1, 2, 3, 4, 5, 6]\n",
    "# CASE_NUMBER_LIST_FOR_AVAILABLE_XPASS_SKILL_PROBS_MODEL = [1, 2]\n",
    "# MAPS_XPASS_DIFFICULTY_VALUES_BY_ORIGINAL_EVENT_ID = {}\n",
    "# MAPS_XPASS_SKILL_PROBS_VALUES_BY_PLAYER_ID = {}\n",
    "# INCLUDE_SKILL = True\n",
    "# COLUMNS_OPTIMUM_THRESHOLD_AND_AUC_SCORE_RESULT = [\n",
    "#     \"case_number_xpass_model\",\n",
    "#     \"case_number_xpass_skill_probs_model\",\n",
    "#     \"optimum_threshold\",\n",
    "#     \"auc_score\"\n",
    "# ]\n",
    "# DIRECTORY_MODEL = \"data/model_xpass_new/\"\n",
    "# FILENAME_DATA_TEST = \"xpass_dataset_for_accuracy_test.csv\"\n",
    "\n",
    "# # Difficulty Value : Change all numeric columns with StandardScaler\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# columns_minmax_scaler = [\"distance_pass\", \"num_opponent_in_path\", \"num_opponent_in_path_receiver\",\n",
    "#                         \"distance_opponent\", \"distance_receiver_opponent\",\n",
    "#                         \"num_opponent_0_and_45_before_midpoint_actor\",\n",
    "#                         \"num_opponent_0_and_45_after_midpoint_actor\",\n",
    "#                         \"num_opponent_0_and_45_before_midpoint_receiver\",\n",
    "#                         \"num_opponent_0_and_45_after_midpoint_receiver\"]\n",
    "# big_dataframe_xpass_model[columns_minmax_scaler] = scaler.fit_transform(big_dataframe_xpass_model[columns_minmax_scaler])\n",
    "# big_dataframe_xpass_model = big_dataframe_xpass_model[big_dataframe_xpass_model['result_id'].isin([0,1])]\n",
    "\n",
    "# # Player Skill Probabilities : Change all numeric columns with MinMaxScaler\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# columns_minmax_scaler = player_skills_column_included + player_attribute_column_included + [\"statistic_success_action_probs\"]\n",
    "# xpass_player_skill_probs_df[columns_minmax_scaler] = scaler.fit_transform(xpass_player_skill_probs_df[columns_minmax_scaler])\n",
    "\n",
    "# xpass_data_test = big_dataframe_xpass_model\n",
    "\n",
    "# # Construct maps xpass difficulty values and maps accuracy score xpass model\n",
    "# for case_number_xpass_model in CASE_NUMBER_LIST_FOR_AVAILABLE_XPASS_MODEL:\n",
    "#     # Loads xpass difficulty model\n",
    "#     filename_xpass_model = f'xpass_model_case_{case_number_xpass_model}.sav'\n",
    "#     xpass_model = pickle.load(open(DIRECTORY_MODEL + filename_xpass_model, 'rb'))\n",
    "#     feature_names_xpass_model = xpass_model.feature_names_in_\n",
    "\n",
    "#     actual_result_ids = pd.Series(xpass_data_test[\"result_id\"]).tolist()\n",
    "#     original_event_ids = pd.Series(xpass_data_test[\"original_event_id\"]).tolist()\n",
    "#     player_ids = pd.Series(xpass_data_test[\"player_id\"]).tolist()\n",
    "#     xpass_train_data = xpass_data_test[feature_names_xpass_model]\n",
    "#     xpass_difficulty_value = [p[1] for p in xpass_model.predict_proba(xpass_train_data)]\n",
    "    \n",
    "#     for idx, event_id in enumerate(original_event_ids):\n",
    "#         actual_result_id = actual_result_ids[idx]\n",
    "#         xpass_difficulty_this_value = xpass_difficulty_value[idx]\n",
    "#         player_id = player_ids[idx]\n",
    "#         player_data = xpass_player_skill_probs_df[xpass_player_skill_probs_df[\"player_id\"] == player_id]\n",
    "#         if (not player_data.empty):\n",
    "#             MAPS_XPASS_DIFFICULTY_VALUES_BY_ORIGINAL_EVENT_ID[(case_number_xpass_model, event_id)] = xpass_difficulty_this_value\n",
    "\n",
    "# # Construct maps xpass player skill probabilities value\n",
    "# unique_player_ids = list(set(pd.Series(xpass_data_test[\"player_id\"]).tolist()))\n",
    "# for case_number_xpass_skill_probs_model in CASE_NUMBER_LIST_FOR_AVAILABLE_XPASS_SKILL_PROBS_MODEL:\n",
    "#     # Load xpass player skill probs model\n",
    "#     filename_xpass_skill_probs_model = f'xpass_player_skill_probs_model_case_{case_number_xpass_skill_probs_model}.sav'\n",
    "#     xpass_skill_probs_model = pickle.load(open(DIRECTORY_MODEL + filename_xpass_skill_probs_model, 'rb'))\n",
    "#     # feature_names_xpass_skill_probs_model = xpass_skill_probs_model.get_booster().feature_names\n",
    "#     feature_names_xpass_skill_probs_model = xpass_skill_probs_model.feature_names_in_\n",
    "\n",
    "#     for player_id in unique_player_ids:\n",
    "#         xpass_skill_train_data = xpass_player_skill_probs_df[xpass_player_skill_probs_df[\"player_id\"] == player_id][feature_names_xpass_skill_probs_model]\n",
    "#         if (not xpass_skill_train_data.empty):\n",
    "#             xpass_skill_value = xpass_skill_probs_model.predict(xpass_skill_train_data)[0]\n",
    "#             xpass_skill_value = 1 / (1 + math.exp(-1 * xpass_skill_value))\n",
    "#             MAPS_XPASS_SKILL_PROBS_VALUES_BY_PLAYER_ID[(case_number_xpass_skill_probs_model, player_id)] = xpass_skill_value\n",
    "\n",
    "# # Final Calculation and Saving Test Result\n",
    "# empty_threshold_auc_result = pd.DataFrame(columns=COLUMNS_OPTIMUM_THRESHOLD_AND_AUC_SCORE_RESULT, index=[0])\n",
    "# empty_threshold_auc_result_with_skill = pd.DataFrame(columns=COLUMNS_OPTIMUM_THRESHOLD_AND_AUC_SCORE_RESULT, index=[0])\n",
    "# list_color_12_models = [\n",
    "#     \"#b53a1b\", \"#ef041a\", \"#f8b25d\",\n",
    "#     \"#51c1e3\", \"#3d21a9\", \"#b8f56a\",\n",
    "#     \"#ed5154\", \"#7d5f40\", \"#561294\",\n",
    "#     \"#32075f\", \"#7000aa\", \"#65c5c6\"\n",
    "# ]\n",
    "# for case_number_xpass_model in CASE_NUMBER_LIST_FOR_AVAILABLE_XPASS_MODEL:\n",
    "#     for case_number_xpass_skill_probs_model in CASE_NUMBER_LIST_FOR_AVAILABLE_XPASS_SKILL_PROBS_MODEL:\n",
    "#         list_actual_result_values = []\n",
    "#         list_predicted_result_values_without_skill = []\n",
    "#         list_predicted_result_values_include_skill = []\n",
    "#         for _, xpass_row_data in xpass_data_test.iterrows():\n",
    "#             actual_result_id = xpass_row_data[\"result_id\"]\n",
    "#             original_event_id = xpass_row_data[\"original_event_id\"]\n",
    "#             related_player_id = xpass_row_data[\"player_id\"]\n",
    "#             xpass_skill_train_data = xpass_player_skill_probs_df[xpass_player_skill_probs_df[\"player_id\"] == related_player_id][feature_names_xpass_skill_probs_model]\n",
    "#             if (not xpass_skill_train_data.empty):\n",
    "#                 xpass_difficulty_value = MAPS_XPASS_DIFFICULTY_VALUES_BY_ORIGINAL_EVENT_ID[(case_number_xpass_model, original_event_id)]\n",
    "#                 xpass_skill_value = MAPS_XPASS_SKILL_PROBS_VALUES_BY_PLAYER_ID[(case_number_xpass_skill_probs_model, related_player_id)]\n",
    "#                 list_actual_result_values.append(actual_result_id)\n",
    "#                 list_predicted_result_values_without_skill.append(xpass_difficulty_value)\n",
    "#                 list_predicted_result_values_include_skill.append(xpass_difficulty_value * xpass_skill_value)\n",
    "        \n",
    "#         with_skill_precisions, with_skill_recalls, with_skill_thresholds = metrics.precision_recall_curve(list_actual_result_values, list_predicted_result_values_include_skill)\n",
    "#         without_skill_precisions, without_skill_recalls, without_skill_thresholds = metrics.precision_recall_curve(list_actual_result_values, list_predicted_result_values_without_skill)\n",
    "        \n",
    "#         # UNCOMMENT THIS SNIPPET IF NEEDED !!\n",
    "#         fscores = (2 * without_skill_precisions * without_skill_recalls) / (without_skill_precisions + without_skill_recalls)\n",
    "#         idx_max = argmax(fscores)\n",
    "#         auc_pr_curve = metrics.auc(without_skill_recalls, without_skill_precisions)\n",
    "#         maps_new_row = {\n",
    "#             \"case_number_xpass_model\" : case_number_xpass_model,\n",
    "#             \"case_number_xpass_skill_probs_model\" : case_number_xpass_skill_probs_model,\n",
    "#             \"optimum_threshold\" : without_skill_thresholds[idx_max],\n",
    "#             \"auc_score\" : auc_pr_curve \n",
    "#         }\n",
    "#         new_row = pd.DataFrame(maps_new_row, index=[0])\n",
    "#         empty_threshold_auc_result = pd.concat([new_row, empty_threshold_auc_result.loc[:]]).reset_index(drop=True)\n",
    "\n",
    "#         fscores = (2 * with_skill_precisions * with_skill_recalls) / (with_skill_precisions + with_skill_recalls)\n",
    "#         idx_max = argmax(fscores)\n",
    "#         auc_pr_curve = metrics.auc(with_skill_recalls, with_skill_precisions)\n",
    "#         maps_new_row = {\n",
    "#             \"case_number_xpass_model\" : case_number_xpass_model,\n",
    "#             \"case_number_xpass_skill_probs_model\" : case_number_xpass_skill_probs_model,\n",
    "#             \"optimum_threshold\" : with_skill_thresholds[idx_max],\n",
    "#             \"auc_score\" : auc_pr_curve \n",
    "#         }\n",
    "#         new_row = pd.DataFrame(maps_new_row, index=[0])\n",
    "#         empty_threshold_auc_result_with_skill = pd.concat([new_row, empty_threshold_auc_result_with_skill.loc[:]]).reset_index(drop=True)\n",
    "\n",
    "#         # UNCOMMENT THIS SNIPPET IF NEEDED !!\n",
    "#         # label = f'Model number difficulty : {case_number_xpass_model}. Model number skill : {case_number_xpass_skill_probs_model}'\n",
    "#         # final_color = list_color_12_models[0]\n",
    "#         # del list_color_12_models[0]\n",
    "#         # # plt.axis([0.9, 1, 0.8, 0.9])\n",
    "#         # plt.plot(without_skill_recalls, without_skill_precisions, marker=\".\", color=final_color, label=label)\n",
    "#         # plt.scatter(without_skill_recalls[idx_max], without_skill_precisions[idx_max], marker='o', color='black', label='Best')\n",
    "\n",
    "#         # label = f'Model number difficulty : {case_number_xpass_model}. Model number skill : {case_number_xpass_skill_probs_model}'\n",
    "#         # final_color = list_color_12_models[0]\n",
    "#         # del list_color_12_models[0]\n",
    "#         # # plt.axis([0.9, 1, 0.8, 0.9])\n",
    "#         # plt.plot(with_skill_recalls, with_skill_precisions, marker=\".\", color=final_color, label=label)\n",
    "#         # plt.scatter(with_skill_recalls[idx_max], with_skill_precisions[idx_max], marker='o', color='black', label='Best')\n",
    "\n",
    "# # UNCOMMENT THIS SNIPPET IF NEEDED !!\n",
    "# filename_threshold_auc_result = f'xpass_threshold_auc_without_skill.csv'\n",
    "# empty_threshold_auc_result.to_csv(DIRECTORY_MODEL + filename_threshold_auc_result)\n",
    "# filename_threshold_auc_result = f'xpass_threshold_auc_include_skill.csv'\n",
    "# empty_threshold_auc_result_with_skill.to_csv(DIRECTORY_MODEL + filename_threshold_auc_result)\n",
    "\n",
    "# # UNCOMMENT THIS SNIPPET IF NEEDED !!\n",
    "# # plt.ylabel(\"Precision\")\n",
    "# # plt.xlabel(\"Recall\")\n",
    "# # plt.title(\"Precision-Recall Curve (XPass Model)\")\n",
    "# # plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "# # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPS_CASE_NUMBER_MODEL = {\n",
    "    \"best\" : {\n",
    "        \"case_number_xpass_model\" : 6,\n",
    "        \"case_number_xpass_skill_probs_model\" : 1\n",
    "    }\n",
    "}\n",
    "MAPS_COMPETITIONS_AND_EVENT_ID_DIRECTORY = {\n",
    "    (55, 43) : {\n",
    "        \"competition_name\" : \"UEFA Euro 2020\"\n",
    "    },\n",
    "    (43, 106) : {\n",
    "        \"competition_name\" : \"FIFA World Cup 2022\"\n",
    "    }\n",
    "}\n",
    "DIRECTORY_MODEL = \"data/model_xpass_new/\"\n",
    "\n",
    "# Helper Functions\n",
    "def calculate_standardscaler_value(row, column_name, std_value, mean_value):\n",
    "    return (row[column_name] - mean_value) / std_value\n",
    "\n",
    "def convert_all_numeric_columns_with_standard_scaler(df_data, column_names, df_description_numeric):\n",
    "    for column_name in column_names:\n",
    "        std_value_this_column = df_description_numeric[column_name][\"std\"]\n",
    "        mean_value_this_column = df_description_numeric[column_name][\"mean\"]\n",
    "        df_data[column_name] = df_data.apply(lambda x : calculate_standardscaler_value(x, column_name, std_value_this_column, mean_value_this_column), axis=1)\n",
    "    return df_data\n",
    "\n",
    "def calculate_minmaxscaler_value(row, column_name, min_value, max_value):\n",
    "    return ((row[column_name] - min_value) / (max_value - min_value))\n",
    "\n",
    "def convert_all_numeric_columns_with_min_max_scaler(df_data, column_names, df_description_numeric):\n",
    "    for column_name in column_names:\n",
    "        min_value_this_column = df_description_numeric[column_name][\"min\"]\n",
    "        max_value_this_column = df_description_numeric[column_name][\"max\"]\n",
    "        df_data[column_name] = df_data.apply(lambda x : calculate_minmaxscaler_value(x, column_name, min_value_this_column, max_value_this_column), axis=1)\n",
    "    return df_data\n",
    "\n",
    "def preprocess_player_skill_probs_df(player_skill_probs_df):\n",
    "    # 1. Change all numeric columns with MinMaxScaler\n",
    "    columns_minmax_scaler = player_attribute_column_included + player_skills_column_included\n",
    "    # Load Description for all Numeric Columns from External CSV\n",
    "    filename = 'xpass_skill_probs_description_numeric_data.csv'\n",
    "    df_description_numeric = pd.read_csv(DIRECTORY_MODEL + filename, index_col=0)\n",
    "    # Preprocess to minmax scaler\n",
    "    player_skill_probs_df = convert_all_numeric_columns_with_standard_scaler(player_skill_probs_df, columns_minmax_scaler, df_description_numeric)\n",
    "\n",
    "    return player_skill_probs_df\n",
    "\n",
    "# Preprocessed for xpass difficulty dataset\n",
    "scaler = preprocessing.StandardScaler()\n",
    "columns_minmax_scaler = [\"distance_pass\", \"num_opponent_in_path\", \"num_opponent_in_path_receiver\",\n",
    "                        \"distance_opponent\", \"distance_receiver_opponent\",\n",
    "                        \"num_opponent_0_and_45_before_midpoint_actor\",\n",
    "                        \"num_opponent_0_and_45_after_midpoint_actor\",\n",
    "                        \"num_opponent_0_and_45_before_midpoint_receiver\",\n",
    "                        \"num_opponent_0_and_45_after_midpoint_receiver\"]\n",
    "big_dataframe_xpass_model[columns_minmax_scaler] = scaler.fit_transform(big_dataframe_xpass_model[columns_minmax_scaler])\n",
    "big_dataframe_xpass_model = big_dataframe_xpass_model[big_dataframe_xpass_model['result_id'].isin([0,1])]\n",
    "\n",
    "# # Preprocessed for xpass player skill probs dataset\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# columns_minmax_scaler = player_skills_column_included + player_attribute_column_included + [\"statistic_success_action_probs\"]\n",
    "# xpass_player_skill_probs_df[columns_minmax_scaler] = scaler.fit_transform(xpass_player_skill_probs_df[columns_minmax_scaler])\n",
    "\n",
    "# Calculate ratings for each players for passing\n",
    "\n",
    "for competition_id, season_id in list(MAPS_COMPETITIONS_AND_EVENT_ID_DIRECTORY.keys()):\n",
    "    competition_name = MAPS_COMPETITIONS_AND_EVENT_ID_DIRECTORY[(competition_id, season_id)][\"competition_name\"]\n",
    "    filename_maps_competition_and_event_ids = f'xpass_map_competition_and_event_id_for_{competition_name}.csv'\n",
    "    maps_competition_and_event_ids_df = pd.read_csv(DIRECTORY_MODEL + filename_maps_competition_and_event_ids)\n",
    "    list_related_event_ids_this_competition = pd.Series(maps_competition_and_event_ids_df['event_id_related']).tolist()\n",
    "    \n",
    "    filename_vaep_ranking_this_competition = f'vaep_players_ranking_for_competition_{competition_name}.csv'\n",
    "    directory_vaep_ranking = \"data/players_skill_dataset/\"\n",
    "    vaep_ranking_df_this_competition = pd.read_csv(directory_vaep_ranking + filename_vaep_ranking_this_competition)\n",
    "\n",
    "    for scenario in list(MAPS_CASE_NUMBER_MODEL.keys()):\n",
    "        case_number_xpass_model = MAPS_CASE_NUMBER_MODEL[scenario][\"case_number_xpass_model\"]\n",
    "        case_number_xpass_skill_model = MAPS_CASE_NUMBER_MODEL[scenario][\"case_number_xpass_skill_probs_model\"]\n",
    "        empty_df_result = pd.DataFrame(columns=player_skills_column_included + player_attribute_column_included + ['statistic_pass_contribution'], index=[0])\n",
    "\n",
    "        for _, row_player in vaep_ranking_df_this_competition.iterrows():\n",
    "            player_id = row_player['player_id']\n",
    "            maps_event_id_with_difficulty_value = {}\n",
    "            related_events_with_this_player = big_dataframe_xpass_model \\\n",
    "                    [(big_dataframe_xpass_model['original_event_id'].isin(list_related_event_ids_this_competition)) & \n",
    "                    (big_dataframe_xpass_model['player_id'] == player_id)]\n",
    "            event_ids_list_for_this_player = pd.Series(related_events_with_this_player['original_event_id']).tolist()\n",
    "            \n",
    "            # Give score for difficulty\n",
    "            filename_xpass_model = f'xpass_model_case_{case_number_xpass_model}.sav'\n",
    "            xpass_model = pickle.load(open(DIRECTORY_MODEL + filename_xpass_model, 'rb'))\n",
    "            feature_names_xpass_model = xpass_model.feature_names_in_\n",
    "            if (not related_events_with_this_player.empty):\n",
    "                train_data = related_events_with_this_player[feature_names_xpass_model]\n",
    "                xpass_difficulty_value = [p[1] for p in xpass_model.predict_proba(train_data)]\n",
    "                for idx, event_id in enumerate(event_ids_list_for_this_player):\n",
    "                    maps_event_id_with_difficulty_value[event_id] = 1 - xpass_difficulty_value[idx]\n",
    "            \n",
    "            # Give score for player skill\n",
    "            filename_xpass_skill_probs_model = f'xpass_player_skill_probs_model_case_{case_number_xpass_skill_model}.sav'\n",
    "            xpass_skill_probs_model = pickle.load(open(DIRECTORY_MODEL + filename_xpass_skill_probs_model, 'rb'))\n",
    "            # feature_names_xpass_skill_probs_model = xpass_skill_probs_model.get_booster().feature_names\n",
    "            feature_names_xpass_skill_probs_model = xpass_skill_probs_model.feature_names_in_\n",
    "            train_data = pd.DataFrame(columns=player_skills_column_included + player_attribute_column_included, index=[0])\n",
    "            row_train_data = {}\n",
    "            for skill in player_skills_column_included:\n",
    "                row_train_data[skill] = row_player[skill]\n",
    "            for attribute in player_attribute_column_included:\n",
    "                row_train_data[attribute] = row_player[attribute]\n",
    "            row_train_data = pd.DataFrame(row_train_data, index=[0])\n",
    "            train_data = pd.concat([row_train_data, train_data.loc[:]]).reset_index(drop=True)\n",
    "            train_data.dropna(inplace=True)\n",
    "            train_data = preprocess_player_skill_probs_df(train_data)\n",
    "            train_data = train_data[feature_names_xpass_skill_probs_model]\n",
    "            xpass_skill_value = xpass_skill_probs_model.predict(train_data)[0]\n",
    "            xpass_skill_value = 1 / (1 + math.exp(-1 * xpass_skill_value))\n",
    "\n",
    "            # Calculate final player contribution for this competition\n",
    "            total_score_this_player = 0\n",
    "            if (not related_events_with_this_player.empty):\n",
    "                for _, row_event in related_events_with_this_player.iterrows():\n",
    "                    total_score_this_player += row_event['result_id'] * maps_event_id_with_difficulty_value[row_event['original_event_id']] * xpass_skill_value\n",
    "            row_statistic_result = {}\n",
    "            row_statistic_result['player_id'] = row_player['player_id']\n",
    "            row_statistic_result['full_name'] = row_player['full_name']\n",
    "            for skill in player_skills_column_included:\n",
    "                row_statistic_result[skill] = row_player[skill]\n",
    "            for attribute in player_attribute_column_included:\n",
    "                row_statistic_result[attribute] = row_player[attribute]\n",
    "            row_statistic_result['statistic_pass_contribution'] = total_score_this_player\n",
    "            row_statistic_result = pd.DataFrame(row_statistic_result, index=[0])\n",
    "            empty_df_result = pd.concat([row_statistic_result, empty_df_result.loc[:]]).reset_index(drop=True)\n",
    "\n",
    "        filename_player_score_result = f'xpass_contribution_score_player_{scenario}_scenario_{competition_name}.csv'\n",
    "        empty_df_result.to_csv(DIRECTORY_MODEL + filename_player_score_result)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
