{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from socceraction.data.wyscout import PublicWyscoutLoader\n",
    "from socceraction.spadl.wyscout import convert_to_actions\n",
    "from socceraction.data.opta import OptaLoader\n",
    "from socceraction.data.statsbomb import StatsBombLoader\n",
    "from socceraction.spadl.config import actiontypes, bodyparts\n",
    "import socceraction.spadl as spadl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wyscout = PublicWyscoutLoader(root=\"data/wyscout\")\n",
    "api_opta = OptaLoader(root=\"data/opta\")\n",
    "# api_statsbomb = StatsBombLoader(root=\"data/statsbomb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_id : 0   action_name : pass\n",
      "action_id : 1   action_name : cross\n",
      "action_id : 2   action_name : throw_in\n",
      "action_id : 3   action_name : freekick_crossed\n",
      "action_id : 4   action_name : freekick_short\n",
      "action_id : 5   action_name : corner_crossed\n",
      "action_id : 6   action_name : corner_short\n",
      "action_id : 7   action_name : take_on\n",
      "action_id : 8   action_name : foul\n",
      "action_id : 9   action_name : tackle\n",
      "action_id : 10   action_name : interception\n",
      "action_id : 11   action_name : shot\n",
      "action_id : 12   action_name : shot_penalty\n",
      "action_id : 13   action_name : shot_freekick\n",
      "action_id : 14   action_name : keeper_save\n",
      "action_id : 15   action_name : keeper_claim\n",
      "action_id : 16   action_name : keeper_punch\n",
      "action_id : 17   action_name : keeper_pick_up\n",
      "action_id : 18   action_name : clearance\n",
      "action_id : 19   action_name : bad_touch\n",
      "action_id : 20   action_name : non_action\n",
      "action_id : 21   action_name : dribble\n",
      "action_id : 22   action_name : goalkick\n"
     ]
    }
   ],
   "source": [
    "for idx, action_name in enumerate(actiontypes):\n",
    "    print(f'action_id : {idx}   action_name : {action_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bodypart_id : 0   bodypart_name : foot\n",
      "bodypart_id : 1   bodypart_name : head\n",
      "bodypart_id : 2   bodypart_name : other\n",
      "bodypart_id : 3   bodypart_name : head/other\n",
      "bodypart_id : 4   bodypart_name : foot_left\n",
      "bodypart_id : 5   bodypart_name : foot_right\n"
     ]
    }
   ],
   "source": [
    "for idx, bodypart_name in enumerate(bodyparts):\n",
    "    print(f'bodypart_id : {idx}   bodypart_name : {bodypart_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_events_df_to_spadl(events_df, home_team_id):\n",
    "    spadl_events_df = convert_to_actions(events_df, home_team_id)\n",
    "    spadl_events_df['time_seconds'] = spadl_events_df['time_seconds'].astype('float64')\n",
    "    spadl_events_df['timestamp'] = pd.to_datetime(spadl_events_df['time_seconds'], unit='s')\n",
    "    spadl_events_df = spadl.play_left_to_right(spadl_events_df, home_team_id)\n",
    "    return spadl_events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all dataset action specific type, export them to csv files\n",
    "# Pass (action_id = 0), Cross (action_id = 1)\n",
    "PASS_ACTION_ID = [0,1] \n",
    "\n",
    "def collect_raw_pass_spadl_df(source=\"Wyscout\", period=1):\n",
    "    api = api_wyscout\n",
    "    list_competitions_ids = []\n",
    "    list_game_ids = []\n",
    "\n",
    "    competitions_df = api.competitions()\n",
    "    for _, row in competitions_df.iterrows():\n",
    "        list_competitions_ids.append((row['competition_id'], row['season_id']))\n",
    "        \n",
    "    for competition_id, season_id in list_competitions_ids:\n",
    "        games_df = api.games(competition_id, season_id)\n",
    "        for _, row in games_df.iterrows():\n",
    "            list_game_ids.append((row['game_id'], row['home_team_id'], row['away_team_id']))\n",
    "            \n",
    "    for game_id, home_team_id, away_team_id in list_game_ids:\n",
    "        this_game_events_df = api.events(game_id)\n",
    "        this_game_events_spadl_df = convert_events_df_to_spadl(this_game_events_df, home_team_id)\n",
    "        this_game_events_spadl_df = this_game_events_spadl_df[this_game_events_spadl_df['type_id'].isin(PASS_ACTION_ID)]\n",
    "        if (period != None):\n",
    "            this_game_events_spadl_df = this_game_events_spadl_df[this_game_events_spadl_df['period_id'] == period]\n",
    "        else:\n",
    "            this_game_events_spadl_df = this_game_events_spadl_df[this_game_events_spadl_df['period_id'] == 1]\n",
    "        \n",
    "        # Export to external csv iteratively\n",
    "        this_game_events_spadl_df.to_csv(f'data/training_data_xpass_wyscout/{game_id}_{home_team_id}_{away_team_id}_xpass_data.csv')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DRIVER (comment it if csv files already loaded)\n",
    "# collect_raw_pass_spadl_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv datas already retrieved then concat them into one big dataframe\n",
    "import os\n",
    "\n",
    "DIRECTORY_XPASS_CSV_DATAS = \"data/training_data_xpass_wyscout\"\n",
    "\n",
    "def load_and_concat_xpass_df_from_csv():\n",
    "    list_pass_event_df = []\n",
    "    for filename in os.listdir(DIRECTORY_XPASS_CSV_DATAS):\n",
    "        f = os.path.join(DIRECTORY_XPASS_CSV_DATAS, filename)\n",
    "        if os.path.isfile(f):\n",
    "            pass_event_df = pd.read_csv(f)\n",
    "            list_pass_event_df.append(pass_event_df)\n",
    "    return pd.concat(list_pass_event_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataframe_xpass_model = load_and_concat_xpass_df_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_x</th>\n",
       "      <th>start_y</th>\n",
       "      <th>end_x</th>\n",
       "      <th>end_y</th>\n",
       "      <th>bodypart_id</th>\n",
       "      <th>result_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.50</td>\n",
       "      <td>35.36</td>\n",
       "      <td>49.35</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.35</td>\n",
       "      <td>34.00</td>\n",
       "      <td>43.05</td>\n",
       "      <td>35.36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.05</td>\n",
       "      <td>35.36</td>\n",
       "      <td>33.60</td>\n",
       "      <td>44.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.60</td>\n",
       "      <td>44.20</td>\n",
       "      <td>93.45</td>\n",
       "      <td>63.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.35</td>\n",
       "      <td>10.88</td>\n",
       "      <td>9.45</td>\n",
       "      <td>19.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_x  start_y  end_x  end_y  bodypart_id  result_id\n",
       "0    52.50    35.36  49.35  34.00            0          1\n",
       "1    49.35    34.00  43.05  35.36            0          1\n",
       "2    43.05    35.36  33.60  44.20            0          1\n",
       "3    33.60    44.20  93.45  63.92            0          0\n",
       "4     7.35    10.88   9.45  19.72            1          0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT ONLY FEATURED COLUMN FROM BIG DATASETS\n",
    "features_column_included = [\"start_x\", \"start_y\", \"end_x\", \"end_y\", \"bodypart_id\", \"result_id\"]\n",
    "big_dataframe_xpass_model = big_dataframe_xpass_model[[c for c in big_dataframe_xpass_model.columns if c in features_column_included]]\n",
    "big_dataframe_xpass_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    719820\n",
      "0    154235\n",
      "2      3379\n",
      "Name: result_id, dtype: int64\n",
      "1.0    719820\n",
      "0.0    154235\n",
      "Name: result_id, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.38      0.50     61738\n",
      "         1.0       0.88      0.97      0.92    287884\n",
      "\n",
      "    accuracy                           0.87    349622\n",
      "   macro avg       0.81      0.68      0.71    349622\n",
      "weighted avg       0.86      0.87      0.85    349622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FEATURE PREPROCESSING BIG DATASETS AND CREATE XGBOOST MODEL\n",
    "# 1. Change start_x, start_y, end_x, end_y with StandardScaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "columns = [\"start_x\", \"start_y\", \"end_x\", \"end_y\"]\n",
    "big_dataframe_xpass_model[columns] = scaler.fit_transform(big_dataframe_xpass_model[columns])\n",
    "\n",
    "# 2. Check if data is unbalanced. If it is unbalanced, then do method to oversize the sample\n",
    "print(big_dataframe_xpass_model['result_id'].value_counts())\n",
    "\n",
    "# 3. Change result_id label into float64 type\n",
    "big_dataframe_xpass_model['result_id'] = big_dataframe_xpass_model['result_id'].astype('float64')\n",
    "\n",
    "# 4. Remove dataframe instead of having result_id (0,1) --> (fail, success)\n",
    "big_dataframe_xpass_model = big_dataframe_xpass_model[big_dataframe_xpass_model['result_id'].isin([0,1])]\n",
    "print(big_dataframe_xpass_model['result_id'].value_counts())\n",
    "\n",
    "# 5. Split train data and test data from Big Datasets\n",
    "all_feature_columns = [\"start_x\", \"start_y\", \"end_x\", \"end_y\", \"bodypart_id\"]\n",
    "X_train = big_dataframe_xpass_model[all_feature_columns]\n",
    "Y_train = big_dataframe_xpass_model[\"result_id\"]\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train, Y_train, test_size=0.4)\n",
    "\n",
    "# 6. Train XGBoost Model \n",
    "modelXGB = XGBClassifier()\n",
    "modelXGB.fit(X_train_split, y_train_split)\n",
    "\n",
    "# 7. Predict Testing Data\n",
    "y_predict = modelXGB.predict(X_test_split)\n",
    "\n",
    "# 8. Display classification report\n",
    "print(classification_report(y_test_split, y_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
